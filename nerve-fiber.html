<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistics with R</title>
  <meta name="description" content="Syllabus for the course ‘Statistics with R’">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Syllabus for the course ‘Statistics with R’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistics with R" />
  
  <meta name="twitter:description" content="Syllabus for the course ‘Statistics with R’" />
  

<meta name="author" content="Douwe Molenaar">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="bias-metabolomics.html">
<link rel="next" href="classifiers.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script language="javascript">
  function toggle(showHideDiv, switchTextDiv) {
  	var ele = document.getElementById(showHideDiv);
	  var text = document.getElementById(switchTextDiv);
	  if(ele.style.display == "block") {
	  	ele.style.display = "none";
	  	text.innerHTML = "Show solution";
	  }
	  else {
	  	ele.style.display = "block";
      text.innerHTML = "Hide solution";
	  }
  }
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="styles/style.css" type="text/css" />
<link rel="stylesheet" href="styles/block_elements.css" type="text/css" />
<link rel="stylesheet" href="styles/localadapt.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Colophon</a></li>
<li class="chapter" data-level="1" data-path="studyguide.html"><a href="studyguide.html"><i class="fa fa-check"></i><b>1</b> Study guide</a><ul>
<li class="chapter" data-level="1.1" data-path="studyguide.html"><a href="studyguide.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="studyguide.html"><a href="studyguide.html#entry-conditions"><i class="fa fa-check"></i><b>1.2</b> Entry conditions</a></li>
<li class="chapter" data-level="1.3" data-path="studyguide.html"><a href="studyguide.html#goal-of-the-course"><i class="fa fa-check"></i><b>1.3</b> Goal of the course</a><ul>
<li class="chapter" data-level="1.3.1" data-path="studyguide.html"><a href="studyguide.html#this-is-not-a-statistics-course"><i class="fa fa-check"></i><b>1.3.1</b> This is not a statistics course</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="studyguide.html"><a href="studyguide.html#workload"><i class="fa fa-check"></i><b>1.4</b> Workload</a></li>
<li class="chapter" data-level="1.5" data-path="studyguide.html"><a href="studyguide.html#setup-and-content-of-the-course"><i class="fa fa-check"></i><b>1.5</b> Setup and content of the course</a><ul>
<li class="chapter" data-level="1.5.1" data-path="studyguide.html"><a href="studyguide.html#walk-in-hours"><i class="fa fa-check"></i><b>1.5.1</b> Walk-in hours</a></li>
<li class="chapter" data-level="1.5.2" data-path="studyguide.html"><a href="studyguide.html#syllabus"><i class="fa fa-check"></i><b>1.5.2</b> Syllabus</a></li>
<li class="chapter" data-level="1.5.3" data-path="studyguide.html"><a href="studyguide.html#assignments"><i class="fa fa-check"></i><b>1.5.3</b> Assignments</a></li>
<li class="chapter" data-level="1.5.4" data-path="studyguide.html"><a href="studyguide.html#assessment"><i class="fa fa-check"></i><b>1.5.4</b> Assessment</a></li>
<li class="chapter" data-level="1.5.5" data-path="studyguide.html"><a href="studyguide.html#evaluation-of-the-course"><i class="fa fa-check"></i><b>1.5.5</b> Evaluation of the course</a></li>
<li class="chapter" data-level="1.5.6" data-path="studyguide.html"><a href="studyguide.html#course-schedule"><i class="fa fa-check"></i><b>1.5.6</b> Course schedule</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Technical background</b></span></li>
<li class="chapter" data-level="2" data-path="quick-start.html"><a href="quick-start.html"><i class="fa fa-check"></i><b>2</b> A quick start</a><ul>
<li class="chapter" data-level="2.1" data-path="quick-start.html"><a href="quick-start.html#what-is-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="quick-start.html"><a href="quick-start.html#resources-for-learning-r"><i class="fa fa-check"></i><b>2.2</b> Resources for learning R</a></li>
<li class="chapter" data-level="2.3" data-path="quick-start.html"><a href="quick-start.html#other-sources-on-the-use-of-r"><i class="fa fa-check"></i><b>2.3</b> Other sources on the use of R</a></li>
<li class="chapter" data-level="2.4" data-path="quick-start.html"><a href="quick-start.html#installation-of-r"><i class="fa fa-check"></i><b>2.4</b> Installation of R</a></li>
<li class="chapter" data-level="2.5" data-path="quick-start.html"><a href="quick-start.html#starting-r"><i class="fa fa-check"></i><b>2.5</b> Starting R</a></li>
<li class="chapter" data-level="2.6" data-path="quick-start.html"><a href="quick-start.html#obtaining-help"><i class="fa fa-check"></i><b>2.6</b> Obtaining help</a></li>
<li class="chapter" data-level="2.7" data-path="quick-start.html"><a href="quick-start.html#an-r-session"><i class="fa fa-check"></i><b>2.7</b> An R-session</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html"><i class="fa fa-check"></i><b>3</b> Elementary data types and operations</a><ul>
<li class="chapter" data-level="3.1" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#the-atomic-data-types"><i class="fa fa-check"></i><b>3.1</b> The atomic data types</a></li>
<li class="chapter" data-level="3.2" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#the-basic-data-object-classes"><i class="fa fa-check"></i><b>3.2</b> The basic data object classes</a></li>
<li class="chapter" data-level="3.3" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#assigning-names-to-r-objects"><i class="fa fa-check"></i><b>3.3</b> Assigning names to R-objects</a><ul>
<li class="chapter" data-level="3.3.1" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#listing-objects-in-memory"><i class="fa fa-check"></i><b>3.3.1</b> Listing objects in memory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#arithmetic-with-vectors-arrays-and-data-frames"><i class="fa fa-check"></i><b>3.4</b> Arithmetic with vectors, arrays, and data frames</a></li>
<li class="chapter" data-level="3.5" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#extracting-and-replacing-parts-of-data-objects"><i class="fa fa-check"></i><b>3.5</b> Extracting and replacing parts of data objects</a><ul>
<li class="chapter" data-level="3.5.1" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#extracting-a-single-sub-object-with-the-double-bracket-index-selector"><i class="fa fa-check"></i><b>3.5.1</b> Extracting a single sub-object with the double bracket index selector <code>[[</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#for-data-frames-and-lists-and-selectors-behave-similarly"><i class="fa fa-check"></i><b>3.5.2</b> For data frames and lists <code>$</code> and <code>[[</code> selectors behave similarly</a></li>
<li class="chapter" data-level="3.5.3" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#complement-syntax"><i class="fa fa-check"></i><b>3.5.3</b> Selecting portions with the single bracket selector <code>[</code></a></li>
<li class="chapter" data-level="3.5.4" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#changing-parts-of-a-vector"><i class="fa fa-check"></i><b>3.5.4</b> Changing parts of a vector</a></li>
<li class="chapter" data-level="3.5.5" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#effect-of-the-selector-operators-on-data-frames"><i class="fa fa-check"></i><b>3.5.5</b> Effect of the selector operators on data frames</a></li>
<li class="chapter" data-level="3.5.6" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#effect-of-the-selector-operators-on-arrays"><i class="fa fa-check"></i><b>3.5.6</b> Effect of the selector operators on arrays</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#removingelements"><i class="fa fa-check"></i><b>3.6</b> Removing elements from objects</a></li>
<li class="chapter" data-level="3.7" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#coercion"><i class="fa fa-check"></i><b>3.7</b> Data class conversion or coercion</a></li>
<li class="chapter" data-level="3.8" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#selection"><i class="fa fa-check"></i>Selection</a></li>
<li class="chapter" data-level="" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#more-selection-vectors-and-sequences"><i class="fa fa-check"></i>More selection, vectors and sequences</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interacting-with-r.html"><a href="interacting-with-r.html"><i class="fa fa-check"></i><b>4</b> Interacting with R</a><ul>
<li class="chapter" data-level="4.1" data-path="interacting-with-r.html"><a href="interacting-with-r.html#controlling-r-from-a-script"><i class="fa fa-check"></i><b>4.1</b> Controlling R from a script</a></li>
<li class="chapter" data-level="4.2" data-path="interacting-with-r.html"><a href="interacting-with-r.html#other-editors"><i class="fa fa-check"></i><b>4.2</b> Other editors</a></li>
<li class="chapter" data-level="4.3" data-path="interacting-with-r.html"><a href="interacting-with-r.html#working-with-packages"><i class="fa fa-check"></i><b>4.3</b> Working with packages</a></li>
<li class="chapter" data-level="4.4" data-path="interacting-with-r.html"><a href="interacting-with-r.html#where-your-packages-are-installed"><i class="fa fa-check"></i><b>4.4</b> Where your packages are installed</a></li>
<li class="chapter" data-level="4.5" data-path="interacting-with-r.html"><a href="interacting-with-r.html#reproducible-research"><i class="fa fa-check"></i><b>4.5</b> Reproducible research</a><ul>
<li class="chapter" data-level="4.5.1" data-path="interacting-with-r.html"><a href="interacting-with-r.html#staying-organized"><i class="fa fa-check"></i><b>4.5.1</b> Staying organized</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="interacting-with-r.html"><a href="interacting-with-r.html#easy-organizing"><i class="fa fa-check"></i><b>4.6</b> Easy organizing with RStudio</a><ul>
<li class="chapter" data-level="" data-path="interacting-with-r.html"><a href="interacting-with-r.html#rmarkdown-documents"><i class="fa fa-check"></i>Rmarkdown documents</a></li>
<li class="chapter" data-level="" data-path="interacting-with-r.html"><a href="interacting-with-r.html#externalizing-code"><i class="fa fa-check"></i>Externalizing code</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="interacting-with-r.html"><a href="interacting-with-r.html#displaying-information-about-your-r-session"><i class="fa fa-check"></i><b>4.7</b> Displaying information about your R session</a></li>
<li class="chapter" data-level="4.8" data-path="interacting-with-r.html"><a href="interacting-with-r.html#citing-r-and-r-packages-in-reports-and-papers"><i class="fa fa-check"></i><b>4.8</b> Citing R and R-packages in reports and papers</a></li>
<li class="chapter" data-level="4.9" data-path="interacting-with-r.html"><a href="interacting-with-r.html#exercise-diversity-of-deep-sea-nematodes"><i class="fa fa-check"></i><b>4.9</b> Exercise: diversity of deep-sea nematodes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="graphics.html"><a href="graphics.html"><i class="fa fa-check"></i><b>5</b> Graphics</a><ul>
<li class="chapter" data-level="5.1" data-path="graphics.html"><a href="graphics.html#the-basics-of-r-graphics"><i class="fa fa-check"></i><b>5.1</b> The basics of R graphics</a></li>
<li class="chapter" data-level="5.2" data-path="graphics.html"><a href="graphics.html#x-y-plots"><i class="fa fa-check"></i><b>5.2</b> X-Y plots</a></li>
<li class="chapter" data-level="5.3" data-path="graphics.html"><a href="graphics.html#histograms"><i class="fa fa-check"></i><b>5.3</b> Histograms</a></li>
<li class="chapter" data-level="5.4" data-path="graphics.html"><a href="graphics.html#boxplots"><i class="fa fa-check"></i><b>5.4</b> Boxplots</a></li>
<li class="chapter" data-level="5.5" data-path="graphics.html"><a href="graphics.html#images-and-contour-plots"><i class="fa fa-check"></i><b>5.5</b> Images and contour plots</a></li>
<li class="chapter" data-level="5.6" data-path="graphics.html"><a href="graphics.html#plotting-a-mathematical-function"><i class="fa fa-check"></i><b>5.6</b> Plotting a mathematical function</a></li>
<li class="chapter" data-level="5.7" data-path="graphics.html"><a href="graphics.html#multiple-figures-in-one-graphical-device"><i class="fa fa-check"></i><b>5.7</b> Multiple figures in one graphical device</a></li>
<li class="chapter" data-level="5.8" data-path="graphics.html"><a href="graphics.html#saving-graphs"><i class="fa fa-check"></i><b>5.8</b> Saving graphs</a></li>
<li class="chapter" data-level="5.9" data-path="graphics.html"><a href="graphics.html#graphical-systems"><i class="fa fa-check"></i><b>5.9</b> Different graphical systems and packages</a></li>
<li class="chapter" data-level="5.10" data-path="graphics.html"><a href="graphics.html#exercises-1"><i class="fa fa-check"></i><b>5.10</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#simple-curves"><i class="fa fa-check"></i>Simple curves</a></li>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#human-population-growth"><i class="fa fa-check"></i>Human population growth</a></li>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#toxic-ammonia"><i class="fa fa-check"></i>Toxic ammonia</a></li>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#the-iris-data-set"><i class="fa fa-check"></i>The iris data set</a></li>
<li><a href="graphics.html#automatic-coercion-by-plot">Automatic coercion by <code>plot()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="file-io.html"><a href="file-io.html"><i class="fa fa-check"></i><b>6</b> File input and output</a><ul>
<li class="chapter" data-level="6.1" data-path="file-io.html"><a href="file-io.html#defining-the-path-to-a-file-or-directory"><i class="fa fa-check"></i><b>6.1</b> Defining the path to a file or directory</a></li>
<li class="chapter" data-level="6.2" data-path="file-io.html"><a href="file-io.html#the-working-directory"><i class="fa fa-check"></i><b>6.2</b> The “working directory”</a></li>
<li class="chapter" data-level="6.3" data-path="file-io.html"><a href="file-io.html#using-the-read.table-and-write.table-functions"><i class="fa fa-check"></i><b>6.3</b> Using the <code>read.table</code> and <code>write.table</code> functions</a></li>
<li class="chapter" data-level="6.4" data-path="file-io.html"><a href="file-io.html#reading-data-from-a-webserver"><i class="fa fa-check"></i><b>6.4</b> Reading data from a webserver</a></li>
<li class="chapter" data-level="6.5" data-path="file-io.html"><a href="file-io.html#reading-data-from-compressed-files-and-archives"><i class="fa fa-check"></i><b>6.5</b> Reading data from compressed files and archives</a></li>
<li class="chapter" data-level="6.6" data-path="file-io.html"><a href="file-io.html#inputoutput-with-excel-files-and-database-management-systems"><i class="fa fa-check"></i><b>6.6</b> Input/output with Excel files and database management systems</a></li>
<li class="chapter" data-level="6.7" data-path="file-io.html"><a href="file-io.html#exercises-2"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Programming-with-R.html"><a href="Programming-with-R.html"><i class="fa fa-check"></i><b>7</b> Programming with R</a><ul>
<li class="chapter" data-level="7.1" data-path="Programming-with-R.html"><a href="Programming-with-R.html#defining-a-function"><i class="fa fa-check"></i><b>7.1</b> Defining a function</a></li>
<li class="chapter" data-level="7.2" data-path="Programming-with-R.html"><a href="Programming-with-R.html#program-flow-control"><i class="fa fa-check"></i><b>7.2</b> Program flow control</a></li>
<li class="chapter" data-level="7.3" data-path="Programming-with-R.html"><a href="Programming-with-R.html#literature"><i class="fa fa-check"></i><b>7.3</b> Literature</a></li>
<li class="chapter" data-level="7.4" data-path="Programming-with-R.html"><a href="Programming-with-R.html#exercises-3"><i class="fa fa-check"></i><b>7.4</b> Exercises</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Programming-with-R.html"><a href="Programming-with-R.html#programming-loops"><i class="fa fa-check"></i><b>7.4.1</b> Loops</a></li>
<li class="chapter" data-level="" data-path="Programming-with-R.html"><a href="Programming-with-R.html#diversity-of-deep-sea-nematodes"><i class="fa fa-check"></i>Diversity of deep-sea nematodes</a></li>
<li class="chapter" data-level="" data-path="Programming-with-R.html"><a href="Programming-with-R.html#diversity-indices-a-function-optional"><i class="fa fa-check"></i>Diversity indices – a function (optional)</a></li>
<li class="chapter" data-level="" data-path="Programming-with-R.html"><a href="Programming-with-R.html#rarefaction-diversity-optional"><i class="fa fa-check"></i>Rarefaction diversity (optional)</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Programming-with-R.html"><a href="Programming-with-R.html#add-prog-ex"><i class="fa fa-check"></i><b>7.5</b> Additional programming exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="vectorization.html"><a href="vectorization.html"><i class="fa fa-check"></i><b>8</b> Vectorization</a><ul>
<li class="chapter" data-level="8.1" data-path="vectorization.html"><a href="vectorization.html#the-function-apply"><i class="fa fa-check"></i><b>8.1</b> The function <code>apply()</code></a></li>
<li class="chapter" data-level="8.2" data-path="vectorization.html"><a href="vectorization.html#the-function-tapply"><i class="fa fa-check"></i><b>8.2</b> The function <code id="the-function-tapply">tapply()</code></a></li>
<li class="chapter" data-level="8.3" data-path="vectorization.html"><a href="vectorization.html#the-functions-lapply-and-sapply"><i class="fa fa-check"></i><b>8.3</b> The functions <code>lapply()</code> and <code>sapply()</code></a></li>
<li class="chapter" data-level="8.4" data-path="vectorization.html"><a href="vectorization.html#exercises-4"><i class="fa fa-check"></i><b>8.4</b> Exercises</a><ul>
<li class="chapter" data-level="8.4.1" data-path="vectorization.html"><a href="vectorization.html#permutation-function"><i class="fa fa-check"></i><b>8.4.1</b> A permutation function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reshaping.html"><a href="reshaping.html"><i class="fa fa-check"></i><b>9</b> Reshaping and manipulating complex data</a><ul>
<li class="chapter" data-level="9.1" data-path="reshaping.html"><a href="reshaping.html#the-tidyr-package"><i class="fa fa-check"></i><b>9.1</b> The <code>tidyr</code> package</a></li>
<li class="chapter" data-level="9.2" data-path="reshaping.html"><a href="reshaping.html#the-dplyr-package"><i class="fa fa-check"></i><b>9.2</b> The <code>dplyr</code> package</a></li>
<li class="chapter" data-level="9.3" data-path="reshaping.html"><a href="reshaping.html#exercises-5"><i class="fa fa-check"></i><b>9.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="formulasyntax.html"><a href="formulasyntax.html"><i class="fa fa-check"></i><b>10</b> Using formula syntax</a><ul>
<li class="chapter" data-level="10.1" data-path="formulasyntax.html"><a href="formulasyntax.html#using-formula-syntax-in-plotting"><i class="fa fa-check"></i><b>10.1</b> Using formula syntax in plotting</a></li>
<li class="chapter" data-level="10.2" data-path="formulasyntax.html"><a href="formulasyntax.html#using-formula-syntax-in-model-definition"><i class="fa fa-check"></i><b>10.2</b> Using formula syntax in model definition</a><ul>
<li class="chapter" data-level="10.2.1" data-path="formulasyntax.html"><a href="formulasyntax.html#data-with-a-continuous-explanatory-variable"><i class="fa fa-check"></i><b>10.2.1</b> Data with a continuous explanatory variable</a></li>
<li class="chapter" data-level="10.2.2" data-path="formulasyntax.html"><a href="formulasyntax.html#data-with-two-discrete-explanatory-variables-factors"><i class="fa fa-check"></i><b>10.2.2</b> Data with two discrete explanatory variables (factors)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Applications</b></span></li>
<li class="chapter" data-level="11" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>11</b> The carnival of distributions</a><ul>
<li class="chapter" data-level="11.1" data-path="distributions.html"><a href="distributions.html#distribution-functions"><i class="fa fa-check"></i><b>11.1</b> Distribution functions</a></li>
<li class="chapter" data-level="11.2" data-path="distributions.html"><a href="distributions.html#distribution-functions-in-r"><i class="fa fa-check"></i><b>11.2</b> Distribution functions in R</a></li>
<li class="chapter" data-level="11.3" data-path="distributions.html"><a href="distributions.html#the-exponential-and-poisson-distributions"><i class="fa fa-check"></i><b>11.3</b> The exponential and Poisson distributions</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercises-6"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="distributions.html"><a href="distributions.html#the-bernoulli-and-binomial-distributions"><i class="fa fa-check"></i><b>11.4</b> The Bernoulli and binomial distributions</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercises-7"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="distributions.html"><a href="distributions.html#the-normal-and-standard-normal-distribution"><i class="fa fa-check"></i><b>11.5</b> The normal and standard normal distribution</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="distributions.html"><a href="distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>11.6</b> Student’s t-distribution</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="distributions.html"><a href="distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i><b>11.7</b> The chi-squared distribution</a><ul>
<li class="chapter" data-level="11.7.1" data-path="distributions.html"><a href="distributions.html#application-in-pearsons-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>11.7.1</b> Application in Pearson’s chi-square goodness of fit test</a></li>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="distributions.html"><a href="distributions.html#the-f-distribution"><i class="fa fa-check"></i><b>11.8</b> The F-distribution</a><ul>
<li class="chapter" data-level="11.8.1" data-path="distributions.html"><a href="distributions.html#analysis-of-variance"><i class="fa fa-check"></i><b>11.8.1</b> Analysis of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="linearmodels.html"><a href="linearmodels.html"><i class="fa fa-check"></i><b>12</b> Linear models and ANOVA</a><ul>
<li class="chapter" data-level="12.1" data-path="linearmodels.html"><a href="linearmodels.html#modeling-with-factor-type-predictor-variables"><i class="fa fa-check"></i><b>12.1</b> Modeling with factor-type predictor variables</a><ul>
<li class="chapter" data-level="12.1.1" data-path="linearmodels.html"><a href="linearmodels.html#alternative-dummy-variable-coding-schemes"><i class="fa fa-check"></i><b>12.1.1</b> Alternative dummy variable coding schemes</a></li>
<li class="chapter" data-level="" data-path="linearmodels.html"><a href="linearmodels.html#exercises-8"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="linearmodels.html"><a href="linearmodels.html#two-way-anovafactorial-anova"><i class="fa fa-check"></i><b>12.2</b> Two-way ANOVA/factorial ANOVA</a><ul>
<li class="chapter" data-level="12.2.1" data-path="linearmodels.html"><a href="linearmodels.html#unbalanced-data"><i class="fa fa-check"></i><b>12.2.1</b> Unbalanced data</a></li>
<li class="chapter" data-level="" data-path="linearmodels.html"><a href="linearmodels.html#exercise-5"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="linearmodels.html"><a href="linearmodels.html#combinations-of-numerical-and-discrete-predictors"><i class="fa fa-check"></i><b>12.3</b> Combinations of numerical and discrete predictors</a><ul>
<li class="chapter" data-level="" data-path="linearmodels.html"><a href="linearmodels.html#exercises-9"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="linearmodels.html"><a href="linearmodels.html#the-connection-between-linear-models-and-anova"><i class="fa fa-check"></i><b>12.4</b> The connection between linear models and ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hubble.html"><a href="hubble.html"><i class="fa fa-check"></i><b>13</b> The age of the universe</a><ul>
<li class="chapter" data-level="13.1" data-path="hubble.html"><a href="hubble.html#exercises-10"><i class="fa fa-check"></i><b>13.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="datafabrication.html"><a href="datafabrication.html"><i class="fa fa-check"></i><b>14</b> A case of data fabrication</a><ul>
<li class="chapter" data-level="14.1" data-path="datafabrication.html"><a href="datafabrication.html#exercises-11"><i class="fa fa-check"></i><b>14.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="amt-carrier.html"><a href="amt-carrier.html"><i class="fa fa-check"></i><b>15</b> A critical evaluation of ammonium transporter kinetics</a><ul>
<li class="chapter" data-level="15.1" data-path="amt-carrier.html"><a href="amt-carrier.html#exercises-12"><i class="fa fa-check"></i><b>15.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="bias-metabolomics.html"><a href="bias-metabolomics.html"><i class="fa fa-check"></i><b>16</b> Bias in metabolomics data</a><ul>
<li class="chapter" data-level="16.1" data-path="bias-metabolomics.html"><a href="bias-metabolomics.html#exercises-13"><i class="fa fa-check"></i><b>16.1</b> Exercises</a><ul>
<li class="chapter" data-level="16.1.1" data-path="bias-metabolomics.html"><a href="bias-metabolomics.html#an-alternative-solution-generalized-additive-modeling-optional"><i class="fa fa-check"></i><b>16.1.1</b> An alternative solution: Generalized additive modeling (optional)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nerve-fiber.html"><a href="nerve-fiber.html"><i class="fa fa-check"></i><b>17</b> Correlation between fiber density and episodic memory?</a><ul>
<li class="chapter" data-level="17.1" data-path="nerve-fiber.html"><a href="nerve-fiber.html#exercises-14"><i class="fa fa-check"></i><b>17.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="classifiers.html"><a href="classifiers.html"><i class="fa fa-check"></i><b>18</b> Logistic regression</a><ul>
<li class="chapter" data-level="18.1" data-path="classifiers.html"><a href="classifiers.html#classifiers"><i class="fa fa-check"></i><b>18.1</b> Classifiers</a></li>
<li class="chapter" data-level="18.2" data-path="classifiers.html"><a href="classifiers.html#logistic-regression"><i class="fa fa-check"></i><b>18.2</b> Logistic regression</a><ul>
<li class="chapter" data-level="18.2.1" data-path="classifiers.html"><a href="classifiers.html#logistic-regression-a-case-of-generalized-linear-modeling"><i class="fa fa-check"></i><b>18.2.1</b> Logistic Regression: a case of Generalized Linear Modeling</a></li>
<li class="chapter" data-level="18.2.2" data-path="classifiers.html"><a href="classifiers.html#logistic-regression-in-r"><i class="fa fa-check"></i><b>18.2.2</b> Logistic regression in R</a></li>
<li class="chapter" data-level="18.2.3" data-path="classifiers.html"><a href="classifiers.html#exercises-15"><i class="fa fa-check"></i><b>18.2.3</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html"><i class="fa fa-check"></i><b>19</b> Classification of dairy bacteria</a><ul>
<li class="chapter" data-level="19.1" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#exercises-16"><i class="fa fa-check"></i><b>19.1</b> Exercises</a><ul>
<li class="chapter" data-level="19.1.1" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#description-of-the-data"><i class="fa fa-check"></i><b>19.1.1</b> Description of the data</a></li>
<li class="chapter" data-level="19.1.2" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#data-conversion"><i class="fa fa-check"></i><b>19.1.2</b> Data conversion</a></li>
<li class="chapter" data-level="19.1.3" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#data-analysis"><i class="fa fa-check"></i><b>19.1.3</b> Data analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="naivebayes.html"><a href="naivebayes.html"><i class="fa fa-check"></i><b>20</b> Naïve Bayes classifiers</a><ul>
<li class="chapter" data-level="20.1" data-path="naivebayes.html"><a href="naivebayes.html#the-naive-bayes-classifier"><i class="fa fa-check"></i><b>20.1</b> The Naive Bayes classifier</a></li>
<li class="chapter" data-level="20.2" data-path="naivebayes.html"><a href="naivebayes.html#a-crime-scene"><i class="fa fa-check"></i><b>20.2</b> A crime scene</a></li>
<li class="chapter" data-level="20.3" data-path="naivebayes.html"><a href="naivebayes.html#reconstructing-bayes-lawtheorem"><i class="fa fa-check"></i><b>20.3</b> Reconstructing Bayes law/theorem</a></li>
<li class="chapter" data-level="20.4" data-path="naivebayes.html"><a href="naivebayes.html#deciding-on-the-class"><i class="fa fa-check"></i><b>20.4</b> Deciding on the class</a></li>
<li class="chapter" data-level="20.5" data-path="naivebayes.html"><a href="naivebayes.html#continuous-predicting-variables"><i class="fa fa-check"></i><b>20.5</b> Continuous predicting variables</a></li>
<li class="chapter" data-level="20.6" data-path="naivebayes.html"><a href="naivebayes.html#combining-information-from-different-predictor-variables"><i class="fa fa-check"></i><b>20.6</b> Combining information from different predictor variables</a></li>
<li class="chapter" data-level="20.7" data-path="naivebayes.html"><a href="naivebayes.html#exercises-17"><i class="fa fa-check"></i><b>20.7</b> Exercises</a><ul>
<li class="chapter" data-level="20.7.1" data-path="naivebayes.html"><a href="naivebayes.html#predicting-iris-species"><i class="fa fa-check"></i><b>20.7.1</b> Predicting iris species</a></li>
<li class="chapter" data-level="20.7.2" data-path="naivebayes.html"><a href="naivebayes.html#predicting-income"><i class="fa fa-check"></i><b>20.7.2</b> Predicting income</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="resampling-techniques.html"><a href="resampling-techniques.html"><i class="fa fa-check"></i><b>21</b> Resampling techniques</a><ul>
<li class="chapter" data-level="21.1" data-path="resampling-techniques.html"><a href="resampling-techniques.html#bootstrapping"><i class="fa fa-check"></i><b>21.1</b> Bootstrapping</a></li>
<li class="chapter" data-level="21.2" data-path="resampling-techniques.html"><a href="resampling-techniques.html#exercises-18"><i class="fa fa-check"></i><b>21.2</b> Exercises</a><ul>
<li class="chapter" data-level="21.2.1" data-path="resampling-techniques.html"><a href="resampling-techniques.html#medical-patches"><i class="fa fa-check"></i><b>21.2.1</b> Medical patches</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="resampling-techniques.html"><a href="resampling-techniques.html#permutation-test"><i class="fa fa-check"></i><b>21.3</b> Permutation test</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html"><i class="fa fa-check"></i><b>22</b> Numerical differentiation and smoothing</a><ul>
<li class="chapter" data-level="22.1" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html#exercises-19"><i class="fa fa-check"></i><b>22.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="randomnumbers.html"><a href="randomnumbers.html"><i class="fa fa-check"></i><b>23</b> Random numbers</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nerve-fiber" class="section level1">
<h1><span class="header-section-number">CHAPTER 17</span> Correlation between fiber density and episodic memory?</h1>
<p><strong>(Techniques: correlation, outliers, influential points)</strong></p>
<p>In a paper in PNAS a group of scientists claimed that they found a significant relation between the nerve fiber density in certain parts of the brain and episodic memory recollection <span class="citation">(Schott et al. <a href="#ref-Schott2011">2011</a>)</span>. The paper was immediately criticized by <span class="citation">Rousselet and Pernet (<a href="#ref-Rousselet2011">2011</a>)</span> for the lack of robust support for the hypothesis. The figure demonstrating the relation is reproduced below.</p>
<div class="figure"><span id="fig:fig3Schott"></span>
<img src="images/Schott_fig3.png" alt="A copy of Figure 3 from @Schott2011" width="70%" />
<p class="caption">
Figure 17.1: A copy of Figure 3 from <span class="citation">Schott et al. (<a href="#ref-Schott2011">2011</a>)</span>
</p>
</div>
<p>You may immediately notice a problem with these data, namely that the correlation doesn’t seem very strong, and that it seems to depend on just a few <em>influential points</em>, namely two or perhaps three out of 28 points at high fiber density. This could be a problem if the measurements corresponding to those points are special, in the sense that they were measured by somebody else, or if there was something else erratic with those measurements. We express such concerns by saying that these measurements could be outliers. You could also argue that the scientists were very lucky to have picked those two or three subjects that were responsible for the significant correlation. So, we will try to find out which points determine the significance of the correlation. The data are available in <a href="data/nervefiber">data/nervefiber</a>.</p>
<div id="exercises-14" class="section level2">
<h2><span class="header-section-number">17.1</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Reproduce the numbers in the figure, <em>i.e.</em> the Pearson correlation coefficient <span class="math inline">\(r\)</span> and the p-value for the ERC data. Also calculate the Spearman rank correlation coefficients. The latter is a more robust correlation coefficient, <em>i.e.</em> it does not depend on the assumption of a linear relation and homoscedastic normal distribution of the errors.
<div>
<a id="NervefibHead1" href="javascript:toggle('NervefibSol1','NervefibHead1');" >Show solution</a>
</div>
<div id="NervefibSol1" style="display: none">
<p>Loading the data and using the <code>cor.test()</code> function from R</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="kw">file.path</span>(baseurl, <span class="st">&quot;data/nervefiber/nervefiber.tab&quot;</span>)
d &lt;-<span class="st"> </span><span class="kw">read.table</span>(f, <span class="dt">sep=</span><span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">header=</span><span class="ot">TRUE</span>)
<span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>PRC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  d$remembered and d$PRC
## t = 4.744, df = 26, p-value = 6.605e-05
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4130527 0.8406167
## sample estimates:
##       cor 
## 0.6811622</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>ERC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  d$remembered and d$ERC
## t = 4.0527, df = 26, p-value = 0.0004074
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.3244537 0.8077784
## sample estimates:
##      cor 
## 0.622214</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>PRC, <span class="dt">method=</span><span class="st">&quot;spearman&quot;</span>)</code></pre></div>
<pre><code>## Warning in cor.test.default(d$remembered, d$PRC, method = &quot;spearman&quot;):
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  d$remembered and d$PRC
## S = 1770.2, p-value = 0.004988
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.5155416</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>ERC, <span class="dt">method=</span><span class="st">&quot;spearman&quot;</span>)</code></pre></div>
<pre><code>## Warning in cor.test.default(d$remembered, d$ERC, method = &quot;spearman&quot;):
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  d$remembered and d$ERC
## S = 2544.3, p-value = 0.1162
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.3036987</code></pre>
<p>Clearly, a Spearman correlation on the relation of memory performance and ERC density is not significant (at sinificance level 0.05). However, in case of the PRC density the correlation seems to hold even with a rank correlation measure.</p>
</div></li>
<li>Reproduce the graphs in figure 3 of the paper. Include a linear fit for each of the graphs.
<div>
<a id="NervefibHead2" href="javascript:toggle('NervefibSol2','NervefibHead2');" >Show solution</a>
</div>
<div id="NervefibSol2" style="display: none">
<p>We use <code>lm()</code> and <code>predict.lm()</code> to fit and plot lines:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,<span class="dt">nrow=</span><span class="dv">1</span>))
<span class="kw">plot</span>(remembered<span class="op">~</span>PRC, <span class="dt">data=</span>d)
lm.PRC &lt;-<span class="st"> </span><span class="kw">lm</span>(remembered<span class="op">~</span>PRC, <span class="dt">data=</span>d)
<span class="kw">lines</span>(d<span class="op">$</span>PRC,<span class="kw">predict</span>(lm.PRC), <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)
<span class="kw">plot</span>(remembered<span class="op">~</span>ERC, <span class="dt">data=</span>d)
lm.ERC &lt;-<span class="st"> </span><span class="kw">lm</span>(remembered<span class="op">~</span>ERC, <span class="dt">data=</span>d)
<span class="kw">lines</span>(d<span class="op">$</span>ERC,<span class="kw">predict</span>(lm.ERC), <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</code></pre></div>
<p><img src="StatR_files/figure-html/graphs-1.png" width="672" /></p>
</div></li>
<li>Plot the residuals as function of the fitted values for the PRC variable only. What do you notice?
<div>
<a id="NervefibHead3" href="javascript:toggle('NervefibSol3','NervefibHead3');" >Show solution</a>
</div>
<div id="NervefibSol3" style="display: none">
<p>Most notable about the plot is the apparent decreasing variance with increasing predicted value, <em>i.e.</em> the error seems to be heteroscedastic (not drawn from a single distribution).</p>
</div></li>
</ol>
<p>The authors use a linear model (<span class="math inline">\(\text{remembered}_i = \beta_0 + \beta_1 \, \text{density}_i + \epsilon_i\)</span>) to model each of the nerve density variables as a function of the fraction remembered. It is highly questionable whether the data fit to such a linear model, given the fact that most points seem to be located in a cloud below a fiber density of 100, within which there is no clear relation between the two variables.</p>
<ol start="4" style="list-style-type: decimal">
<li>Check whether it is true that the relation is not noticeable below a fiber density of 100.
<div>
<a id="NervefibHead4" href="javascript:toggle('NervefibSol4','NervefibHead4');" >Show solution</a>
</div>
<div id="NervefibSol4" style="display: none">

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subset.PRC &lt;-<span class="st"> </span>d[d<span class="op">$</span>PRC<span class="op">&lt;</span><span class="dv">100</span>,]
<span class="kw">cor.test</span>(subset.PRC<span class="op">$</span>remembered, subset.PRC<span class="op">$</span>PRC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  subset.PRC$remembered and subset.PRC$PRC
## t = 1.026, df = 21, p-value = 0.3166
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.2128870  0.5785824
## sample estimates:
##       cor 
## 0.2184881</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subset.ERC &lt;-<span class="st"> </span>d[d<span class="op">$</span>ERC<span class="op">&lt;</span><span class="dv">100</span>,]
<span class="kw">cor.test</span>(subset.ERC<span class="op">$</span>remembered, subset.ERC<span class="op">$</span>ERC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  subset.ERC$remembered and subset.ERC$ERC
## t = 0.66628, df = 22, p-value = 0.5122
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.2785609  0.5148282
## sample estimates:
##       cor 
## 0.1406395</code></pre>
Clearly, the relation disappears, or becomes unnoticeable within the noise of the measurements.</li>
</ol>
<p>A question you could ask is how much influence each of the points has on the fitted line. The question could be made more precise by asking for their influence on the two parameters, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. We are mostly interested in the influence on the slope parameter <span class="math inline">\(\beta_1\)</span> and in the influence that particular points have on significance of the slope (whether it differs from 0). The rationale behind the question is that you would (or should) want to know what the influence of a single measurement is on the conclusions from the whole study. A single, highly influential measurement deserves attention: was it measured correctly, and if so, what is the cause of its deviation from the other measurements. Since a point may have different effects on the fitted model, there are also different measures of influence. In R these can be calculated using the <code>influence</code> or <code>influence.measures()</code> functions from the standard <code>stats</code> package, to obtain a list or table of different measures for each of the points, or separately using the functions mentioned in the help file of the <code>influence.measures()</code> function. That function also yields a column in which highly influential points (by any of the measures) are marked with an asterisk.</p>
<p>Here, we briefly discuss a few measures of influence (see for example <span class="citation">Faraway (<a href="#ref-Faraway2005">2005</a>)</span> for a more detailed discussion):</p>
<ul>
<li><strong>Hat value</strong>: or <em>leverage</em> is a measure of the distance (Mahalanobis distance is used) of a point to the center of the data set. Points far from that center have a large leverage. They exert a much larger “force” on a fitted line to pass near them than points near the center (hence, the term leverage). Technically, the hat values of a data set are the diagonal elements from the so-called hat matrix <span class="math inline">\(\mathbf{H}\)</span> which is calculated from the values of the independent variables and the number of fitted parameters <span class="math inline">\(p\)</span>. The sum of hat values <span class="math inline">\(h_i\)</span> equals the number of parameters: <span class="math inline">\(\Sigma h_i = p\)</span>. So, on average, a hat value equals <span class="math inline">\(p/n\)</span>, where <span class="math inline">\(n\)</span> is the number of measurements. A rule-of-thumb criterion to decide whether a hat value <span class="math inline">\(h\)</span> is unusually large is <span class="math display">\[
h \geq \text{min} \left[ \frac{2p}{n}, 0.99 \right]
\]</span></li>
<li><strong>Rstudent residual</strong>: (or <em>jackknifed residual</em>) If you remove a point from the data set, a model can be fitted through the remaining data. The deviation <span class="math inline">\(\hat{\epsilon}_i\)</span> of the left-out point from the predicted value using that model, normalized by residual mean squares is a measure of its deviation from the model of the remaining data. Hence you can use this measure to detect an outlier in a data set (although it will often fail when there are multiple outliers, see <span class="citation">Faraway (<a href="#ref-Faraway2005">2005</a>)</span>). The Rstudent residual <span class="math inline">\(t_i\)</span> of point <span class="math inline">\(i\)</span> equals <span class="math display">\[
t_i = \frac{\hat{\epsilon}_i}{\sqrt{\text{residual MS}_{(i)}} \sqrt{1 - h_i}}
\]</span> This residual is approximately student T-distributed with <span class="math inline">\(n-p-1\)</span> degrees of freedom (if the model is correct). So, we can use this to test for significant deviation.</li>
<li><strong>dfbeta</strong>, <strong>dffit</strong>: These measures indicate how the parameters (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <em>etc.</em>) (the dfbeta’s, one for each parameter) of the fit to the dependent variable <span class="math inline">\(Y_i\)</span> will differ when a point <span class="math inline">\(i\)</span> is left out of the data set. Rule-of-thumb cut-off criteria are <span class="math inline">\(|\text{dffit}| \geq 3 \sqrt{\frac{p}{n-p}}\)</span> and <span class="math inline">\(|\text{dfbeta}| \geq 1\)</span>.</li>
<li><strong>Cook’s distance</strong>: Summarizes the effect on the model parameters in a single number per point. <span class="math inline">\(D_i \geq 1\)</span> and <span class="math inline">\(D_i \geq \frac{4}{n}\)</span> are used as criteria to decide which points have unusual Cook’s distances .</li>
</ul>
<div class="rmdtip">
<p>
Consider using the <code>augment()</code> function from the <a href="https://cran.r-project.org/web/packages/broom/vignettes/broom.html"><code>broom</code></a> package. In addition to the fitted values and residuals it yields a data frame with several influence metrics per data point.
</p>
</div>
<ol start="5" style="list-style-type: decimal">
<li>Calculate the hat values or leverages (on the PRC model) and determine whether they are unusually large for some points. Confirm that the sum of leverages equals the number of parameters of the model.
<div>
<a id="NervefibHead5" href="javascript:toggle('NervefibSol5','NervefibHead5');" >Show solution</a>
</div>
<div id="NervefibSol5" style="display: none">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">h &lt;-<span class="st"> </span><span class="kw">hatvalues</span>(lm.PRC)
<span class="kw">plot</span>(h, <span class="dt">pch=</span><span class="kw">as.numeric</span>(h<span class="op">&gt;</span>(<span class="dv">2</span><span class="op">*</span><span class="dv">2</span><span class="op">/</span><span class="kw">length</span>(h))) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</code></pre></div>
<p><img src="StatR_files/figure-html/hatvalues-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># identify(h)</span>
<span class="kw">sum</span>(h)</code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>Points 21, 27 and 28 have a suspiciously high hat value</p>
</div></li>
<li>Calculate the studentized residuals (on the model for PRC) using the <code>rstudent()</code> function. Determine whether they deviate significantly from the expected value (apply a Bonferroni correction for multiple hypothesis testing).
<div>
<a id="NervefibHead6" href="javascript:toggle('NervefibSol6','NervefibHead6');" >Show solution</a>
</div>
<div id="NervefibSol6" style="display: none">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rst &lt;-<span class="st"> </span><span class="kw">rstudent</span>(lm.PRC)
<span class="co"># calculate a cut-off value for t (two-sided), using bonferroni correction</span>
cutoff_t &lt;-<span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span><span class="op">/</span><span class="kw">length</span>(rst), <span class="dt">df=</span><span class="kw">length</span>(rst)<span class="op">-</span><span class="dv">2</span><span class="op">-</span><span class="dv">1</span>)
<span class="co"># two-sided test, cutoff_t is a negative number!</span>
sign.bonf &lt;-<span class="st"> </span><span class="op">-</span><span class="kw">abs</span>(rst) <span class="op">&lt;</span><span class="st"> </span>cutoff_t
<span class="kw">any</span>(sign.bonf)</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># no apparent large deviations according to this criterion</span></code></pre></div>
</div></li>
<li>Calculate Cook’s distances and indicate which points have a high influence based on this parameter.
<div>
<a id="NervefibHead7" href="javascript:toggle('NervefibSol7','NervefibHead7');" >Show solution</a>
</div>
<div id="NervefibSol7" style="display: none">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">cooks.distance</span>(lm.PRC), <span class="dt">pch=</span><span class="kw">as.numeric</span>(<span class="kw">cooks.distance</span>(lm.PRC) <span class="op">&gt;</span><span class="st"> </span><span class="dv">4</span><span class="op">/</span><span class="kw">length</span>(d<span class="op">$</span>PRC))<span class="op">+</span><span class="dv">1</span>)</code></pre></div>
<p><img src="StatR_files/figure-html/cooksdist-1.png" width="672" /></p>
</div></li>
</ol>
<p>The conclusion from all of the tests above are that:</p>
<ul>
<li>There are a few influential points in the data set, but leaving out each individually is unlikely to change the conclusion from the study</li>
<li>The distribution of fiber densities, with a few very high densisties and many low densisties, is such that this fact on its own deserves attention: why do some people have exceptionally high fiber density? What else is special about these people?</li>
<li>The relation between fiber density and memory performance is only visible when people with unusually high fiber density are included</li>
</ul>
<p>The take home-message is that statistical analysis enhances our understanding of the data, but it should not replace it. There is much more to say about these data than the plain conclusion that “there is a significant correlation”.</p>
<p>Below, we investigate to what extent the conclusion “significant effect” depends on the presence of particular points in the data set. As we saw, it completely disappears when only taking data with densities lower than 100.</p>
<ol style="list-style-type: decimal">
<li>For each of the points, calculate the influence that it has on the p-value of the <code>cor.test()</code> by calculating the <span class="math inline">\(\log_{10}(ratio)\)</span> of the p-value of the data set without over that with the point (this is a positive number if the point decreases the p-value, or increases the significance of the correlation). Do this for both ERC and PRC and call the resulting values influence.PRC and influence.ERC, and add them to the data frame. The output of <code>cor.test()</code> is a subclass object of the <code>list</code> class, and the p-value can be extracted by its name <code>p.value</code> from such an object.
<div>
<a id="NervefibHead8" href="javascript:toggle('NervefibSol8','NervefibHead8');" >Show solution</a>
</div>
<div id="NervefibSol8" style="display: none">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">influence.ERC &lt;-<span class="st"> </span><span class="kw">c</span>()
influence.PRC &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="co"># Reference p-values</span>
pv.ERC &lt;-<span class="st"> </span><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>ERC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)<span class="op">$</span>p.value
pv.PRC &lt;-<span class="st"> </span><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>PRC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)<span class="op">$</span>p.value
<span class="co"># In each iteration leave one point out and calculate its influence,</span>
d<span class="op">$</span>influence.PRC =<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(d<span class="op">$</span>remembered), <span class="cf">function</span>(i) {
  <span class="kw">log10</span>(<span class="kw">cor.test</span>(d<span class="op">$</span>remembered[<span class="op">-</span>i], d<span class="op">$</span>ERC[<span class="op">-</span>i], <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)<span class="op">$</span>p.value<span class="op">/</span>pv.ERC)
  })
d<span class="op">$</span>influence.ERC =<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(d<span class="op">$</span>remembered), <span class="cf">function</span>(i) {
  <span class="kw">log10</span>(<span class="kw">cor.test</span>(d<span class="op">$</span>remembered[<span class="op">-</span>i], d<span class="op">$</span>PRC[<span class="op">-</span>i], <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)<span class="op">$</span>p.value<span class="op">/</span>pv.PRC)
  })</code></pre></div>
<p>Using the <code>ggplot2</code> package we can also make a nice graph of the influence:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># library(ggplot2)</span>
<span class="kw">ggplot</span>(d, <span class="kw">aes</span>(<span class="dt">x=</span>ERC, <span class="dt">y=</span>remembered, <span class="dt">color=</span>influence.ERC)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">6</span>, <span class="dt">colour=</span><span class="st">&#39;grey20&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_colour_gradient2</span>(<span class="dt">low=</span><span class="st">&#39;blue&#39;</span>,<span class="dt">high=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="StatR_files/figure-html/fiber02a-1.png" width="0.6\linewidth" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(d, <span class="kw">aes</span>(<span class="dt">x=</span>PRC, <span class="dt">y=</span>remembered, <span class="dt">color=</span>influence.PRC)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">6</span>, <span class="dt">colour=</span><span class="st">&#39;grey20&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_colour_gradient2</span>(<span class="dt">low=</span><span class="st">&#39;blue&#39;</span>,<span class="dt">high=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="StatR_files/figure-html/fiber02a-2.png" width="0.6\linewidth" /></p>
</div></li>
<li>If you study the influence results, you will see that particularly the two points with the largest nerve fiber counts have a large influence on the p-value, amounting to factors of <span class="math inline">\(10^{1.65}=45.2\)</span> and <span class="math inline">\(10^{0.73}=5.4\)</span>, respectively. Remove the one, two and three most positive influential points and re-calculate the p-values. Put them in a table and display them. On how many subjects does the significance of the correlation depend?
<div>
<a id="NervefibHead9" href="javascript:toggle('NervefibSol9','NervefibHead9');" >Show solution</a>
</div>
<div id="NervefibSol9" style="display: none">
<p>First we calculate the order of influence, which returns an index vector, and then we can remove the 1, 2 and 3 most influential points by removing the points with the first 1 <span class="math inline">\(\cdots\)</span> 3 indices.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># creating an empty table</span>
inf.table &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">points.removed=</span><span class="dv">0</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">ERC.pvalue=</span><span class="kw">rep</span>(<span class="ot">NA</span>,<span class="dv">4</span>), <span class="dt">PRC.pvalue=</span><span class="kw">rep</span>(<span class="ot">NA</span>,<span class="dv">4</span>))
PRC.order &lt;-<span class="st"> </span><span class="kw">order</span>(d<span class="op">$</span>influence.PRC, <span class="dt">decreasing=</span><span class="ot">TRUE</span>)
ERC.order &lt;-<span class="st"> </span><span class="kw">order</span>(d<span class="op">$</span>influence.ERC, <span class="dt">decreasing=</span><span class="ot">TRUE</span>)
inf.table[<span class="dv">1</span>,<span class="st">&#39;PRC.pvalue&#39;</span>] &lt;-<span class="st"> </span><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>PRC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)<span class="op">$</span>p.value
inf.table[<span class="dv">1</span>,<span class="st">&#39;ERC.pvalue&#39;</span>] &lt;-<span class="st"> </span><span class="kw">cor.test</span>(d<span class="op">$</span>remembered, d<span class="op">$</span>ERC, <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)<span class="op">$</span>p.value
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>) {
  rd &lt;-<span class="st"> </span>d[PRC.order[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span>i)],]
  inf.table[i<span class="op">+</span><span class="dv">1</span>,<span class="st">&#39;PRC.pvalue&#39;</span>] &lt;-<span class="st"> </span><span class="kw">cor.test</span>(rd<span class="op">$</span>remembered, rd<span class="op">$</span>PRC, <span class="dt">method=</span><span class="st">&#39;pearson&#39;</span>)<span class="op">$</span>p.value
  rd &lt;-<span class="st"> </span>d[ERC.order[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span>i)],]
  inf.table[i<span class="op">+</span><span class="dv">1</span>,<span class="st">&#39;ERC.pvalue&#39;</span>] &lt;-<span class="st"> </span><span class="kw">cor.test</span>(rd<span class="op">$</span>remembered, rd<span class="op">$</span>ERC, <span class="dt">method=</span><span class="st">&#39;pearson&#39;</span>)<span class="op">$</span>p.value
}
inf.table</code></pre></div>
<pre><code>##   points.removed   ERC.pvalue  PRC.pvalue
## 1              0 0.0004073759 0.000066054
## 2              1 0.0183984872 0.002840849
## 3              2 0.1772134107 0.029162011
## 4              3 0.2581785086 0.036217447</code></pre>
<p>It shows that significance depends on 2 or 3 subjects for ERC and PRC, respectively. Again, it shows that the conclusion from the study depends on a tiny subset at high fiber density. That requires additional research and explanation, which the authors do not supply in their paper. Perhaps, that is the most fundamental criticism of this study. The authors hide behind a statistical criterion, as often happens in the medical and psychological literature (see their response to <span class="citation">Rousselet and Pernet (<a href="#ref-Rousselet2011">2011</a>)</span>).</p>
</div></li>
</ol>
<div class="rmdnote">
<p>
Notice how we (as well as the authors) completely ignore the fact that the measurement of the independent variable, PRC or ERC, is likely to contain an error too, and a large one probably, compared to the full range of measurements of fiber densities. The assumption behind the linear model is that the error in the independent variable is very small compared to the range. A large error in fiber density measurement might be a cause for the lack of observed correlation between fiber density and memory performance when only using low densities. A very large error in the independent variables will cause the slope to be biased towards 0. Chapter 5 in <span class="citation"><span class="citation">Faraway (<a href="#ref-Faraway2005">2005</a>)</span></span> gives a discussion of this effect as well as a possible solution to, nevertheless, obtain a good (unbiased) estimate of the slope of a linear regression when the error in the independent variables is of considerable size.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Schott2011">
<p>Schott, B. H., C. Niklas, J. Kaufmann, N. C. Bodammer, J. Machts, H. Schütze, and E. Düzel. 2011. “Fiber Density Between Rhinal Cortex and Activated Ventrolateral Prefrontal Regions Predicts Episodic Memory Performance in Humans.” <em>Proc. Natl. Acad. Sci. U. S. A.</em> 108 (13): 5408–13. doi:<a href="https://doi.org/10.1073/pnas.1013287108">10.1073/pnas.1013287108</a>.</p>
</div>
<div id="ref-Rousselet2011">
<p>Rousselet, G. A., and C. R. Pernet. 2011. “Robust Statistics Show No Evidence for a Relationship Between Fiber Density and Memory Performance.” <em>Proc. Natl. Acad. Sci. U. S. A.</em> 108 (35): E598; author reply E599. doi:<a href="https://doi.org/10.1073/pnas.1109188108">10.1073/pnas.1109188108</a>.</p>
</div>
<div id="ref-Faraway2005">
<p>Faraway, J. 2005. <em>Linear Models with R</em>. Boca Raton, FL, USA: Chapman &amp; Hall/CRC. <a href="http://www.maths.bath.ac.uk/~jjf23/LMR/" class="uri">http://www.maths.bath.ac.uk/~jjf23/LMR/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bias-metabolomics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classifiers.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "libs/mathjax-local/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
