<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistics with R</title>
  <meta name="description" content="Syllabus for the course ‘Statistics with R’">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Syllabus for the course ‘Statistics with R’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistics with R" />
  
  <meta name="twitter:description" content="Syllabus for the course ‘Statistics with R’" />
  

<meta name="author" content="Douwe Molenaar">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="distributions.html">
<link rel="next" href="hubble.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script language="javascript">
  function toggle(showHideDiv, switchTextDiv) {
  	var ele = document.getElementById(showHideDiv);
	  var text = document.getElementById(switchTextDiv);
	  if(ele.style.display == "block") {
	  	ele.style.display = "none";
	  	text.innerHTML = "Show solution";
	  }
	  else {
	  	ele.style.display = "block";
      text.innerHTML = "Hide solution";
	  }
  }
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="styles/style.css" type="text/css" />
<link rel="stylesheet" href="styles/block_elements.css" type="text/css" />
<link rel="stylesheet" href="styles/localadapt.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Colophon</a></li>
<li class="chapter" data-level="1" data-path="studyguide.html"><a href="studyguide.html"><i class="fa fa-check"></i><b>1</b> Study guide</a><ul>
<li class="chapter" data-level="1.1" data-path="studyguide.html"><a href="studyguide.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="studyguide.html"><a href="studyguide.html#entry-conditions"><i class="fa fa-check"></i><b>1.2</b> Entry conditions</a></li>
<li class="chapter" data-level="1.3" data-path="studyguide.html"><a href="studyguide.html#goal-of-the-course"><i class="fa fa-check"></i><b>1.3</b> Goal of the course</a><ul>
<li class="chapter" data-level="1.3.1" data-path="studyguide.html"><a href="studyguide.html#this-is-not-a-statistics-course"><i class="fa fa-check"></i><b>1.3.1</b> This is not a statistics course</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="studyguide.html"><a href="studyguide.html#workload"><i class="fa fa-check"></i><b>1.4</b> Workload</a></li>
<li class="chapter" data-level="1.5" data-path="studyguide.html"><a href="studyguide.html#setup-and-content-of-the-course"><i class="fa fa-check"></i><b>1.5</b> Setup and content of the course</a><ul>
<li class="chapter" data-level="1.5.1" data-path="studyguide.html"><a href="studyguide.html#walk-in-hours"><i class="fa fa-check"></i><b>1.5.1</b> Walk-in hours</a></li>
<li class="chapter" data-level="1.5.2" data-path="studyguide.html"><a href="studyguide.html#syllabus"><i class="fa fa-check"></i><b>1.5.2</b> Syllabus</a></li>
<li class="chapter" data-level="1.5.3" data-path="studyguide.html"><a href="studyguide.html#assignments"><i class="fa fa-check"></i><b>1.5.3</b> Assignments</a></li>
<li class="chapter" data-level="1.5.4" data-path="studyguide.html"><a href="studyguide.html#assessment"><i class="fa fa-check"></i><b>1.5.4</b> Assessment</a></li>
<li class="chapter" data-level="1.5.5" data-path="studyguide.html"><a href="studyguide.html#evaluation-of-the-course"><i class="fa fa-check"></i><b>1.5.5</b> Evaluation of the course</a></li>
<li class="chapter" data-level="1.5.6" data-path="studyguide.html"><a href="studyguide.html#course-schedule"><i class="fa fa-check"></i><b>1.5.6</b> Course schedule</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Technical background</b></span></li>
<li class="chapter" data-level="2" data-path="quick-start.html"><a href="quick-start.html"><i class="fa fa-check"></i><b>2</b> A quick start</a><ul>
<li class="chapter" data-level="2.1" data-path="quick-start.html"><a href="quick-start.html#what-is-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="quick-start.html"><a href="quick-start.html#resources-for-learning-r"><i class="fa fa-check"></i><b>2.2</b> Resources for learning R</a></li>
<li class="chapter" data-level="2.3" data-path="quick-start.html"><a href="quick-start.html#other-sources-on-the-use-of-r"><i class="fa fa-check"></i><b>2.3</b> Other sources on the use of R</a></li>
<li class="chapter" data-level="2.4" data-path="quick-start.html"><a href="quick-start.html#installation-of-r"><i class="fa fa-check"></i><b>2.4</b> Installation of R</a></li>
<li class="chapter" data-level="2.5" data-path="quick-start.html"><a href="quick-start.html#starting-r"><i class="fa fa-check"></i><b>2.5</b> Starting R</a></li>
<li class="chapter" data-level="2.6" data-path="quick-start.html"><a href="quick-start.html#obtaining-help"><i class="fa fa-check"></i><b>2.6</b> Obtaining help</a></li>
<li class="chapter" data-level="2.7" data-path="quick-start.html"><a href="quick-start.html#an-r-session"><i class="fa fa-check"></i><b>2.7</b> An R-session</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html"><i class="fa fa-check"></i><b>3</b> Elementary data types and operations</a><ul>
<li class="chapter" data-level="3.1" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#the-atomic-data-types"><i class="fa fa-check"></i><b>3.1</b> The atomic data types</a></li>
<li class="chapter" data-level="3.2" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#the-basic-data-object-classes"><i class="fa fa-check"></i><b>3.2</b> The basic data object classes</a></li>
<li class="chapter" data-level="3.3" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#assigning-names-to-r-objects"><i class="fa fa-check"></i><b>3.3</b> Assigning names to R-objects</a><ul>
<li class="chapter" data-level="3.3.1" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#listing-objects-in-memory"><i class="fa fa-check"></i><b>3.3.1</b> Listing objects in memory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#arithmetic-with-vectors-arrays-and-data-frames"><i class="fa fa-check"></i><b>3.4</b> Arithmetic with vectors, arrays, and data frames</a></li>
<li class="chapter" data-level="3.5" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#extracting-and-replacing-parts-of-data-objects"><i class="fa fa-check"></i><b>3.5</b> Extracting and replacing parts of data objects</a><ul>
<li class="chapter" data-level="3.5.1" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#extracting-a-single-sub-object-with-the-double-bracket-index-selector"><i class="fa fa-check"></i><b>3.5.1</b> Extracting a single sub-object with the double bracket index selector <code>[[</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#for-data-frames-and-lists-and-selectors-behave-similarly"><i class="fa fa-check"></i><b>3.5.2</b> For data frames and lists <code>$</code> and <code>[[</code> selectors behave similarly</a></li>
<li class="chapter" data-level="3.5.3" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#complement-syntax"><i class="fa fa-check"></i><b>3.5.3</b> Selecting portions with the single bracket selector <code>[</code></a></li>
<li class="chapter" data-level="3.5.4" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#changing-parts-of-a-vector"><i class="fa fa-check"></i><b>3.5.4</b> Changing parts of a vector</a></li>
<li class="chapter" data-level="3.5.5" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#effect-of-the-selector-operators-on-data-frames"><i class="fa fa-check"></i><b>3.5.5</b> Effect of the selector operators on data frames</a></li>
<li class="chapter" data-level="3.5.6" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#effect-of-the-selector-operators-on-arrays"><i class="fa fa-check"></i><b>3.5.6</b> Effect of the selector operators on arrays</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#removingelements"><i class="fa fa-check"></i><b>3.6</b> Removing elements from objects</a></li>
<li class="chapter" data-level="3.7" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#coercion"><i class="fa fa-check"></i><b>3.7</b> Data class conversion or coercion</a></li>
<li class="chapter" data-level="3.8" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#selection"><i class="fa fa-check"></i>Selection</a></li>
<li class="chapter" data-level="" data-path="elementary-datatypes.html"><a href="elementary-datatypes.html#more-selection-vectors-and-sequences"><i class="fa fa-check"></i>More selection, vectors and sequences</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interacting-with-r.html"><a href="interacting-with-r.html"><i class="fa fa-check"></i><b>4</b> Interacting with R</a><ul>
<li class="chapter" data-level="4.1" data-path="interacting-with-r.html"><a href="interacting-with-r.html#controlling-r-from-a-script"><i class="fa fa-check"></i><b>4.1</b> Controlling R from a script</a></li>
<li class="chapter" data-level="4.2" data-path="interacting-with-r.html"><a href="interacting-with-r.html#other-editors"><i class="fa fa-check"></i><b>4.2</b> Other editors</a></li>
<li class="chapter" data-level="4.3" data-path="interacting-with-r.html"><a href="interacting-with-r.html#working-with-packages"><i class="fa fa-check"></i><b>4.3</b> Working with packages</a></li>
<li class="chapter" data-level="4.4" data-path="interacting-with-r.html"><a href="interacting-with-r.html#where-your-packages-are-installed"><i class="fa fa-check"></i><b>4.4</b> Where your packages are installed</a></li>
<li class="chapter" data-level="4.5" data-path="interacting-with-r.html"><a href="interacting-with-r.html#reproducible-research"><i class="fa fa-check"></i><b>4.5</b> Reproducible research</a><ul>
<li class="chapter" data-level="4.5.1" data-path="interacting-with-r.html"><a href="interacting-with-r.html#staying-organized"><i class="fa fa-check"></i><b>4.5.1</b> Staying organized</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="interacting-with-r.html"><a href="interacting-with-r.html#easy-organizing"><i class="fa fa-check"></i><b>4.6</b> Easy organizing with RStudio</a><ul>
<li class="chapter" data-level="" data-path="interacting-with-r.html"><a href="interacting-with-r.html#rmarkdown-documents"><i class="fa fa-check"></i>Rmarkdown documents</a></li>
<li class="chapter" data-level="" data-path="interacting-with-r.html"><a href="interacting-with-r.html#externalizing-code"><i class="fa fa-check"></i>Externalizing code</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="interacting-with-r.html"><a href="interacting-with-r.html#displaying-information-about-your-r-session"><i class="fa fa-check"></i><b>4.7</b> Displaying information about your R session</a></li>
<li class="chapter" data-level="4.8" data-path="interacting-with-r.html"><a href="interacting-with-r.html#citing-r-and-r-packages-in-reports-and-papers"><i class="fa fa-check"></i><b>4.8</b> Citing R and R-packages in reports and papers</a></li>
<li class="chapter" data-level="4.9" data-path="interacting-with-r.html"><a href="interacting-with-r.html#exercise-diversity-of-deep-sea-nematodes"><i class="fa fa-check"></i><b>4.9</b> Exercise: diversity of deep-sea nematodes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="graphics.html"><a href="graphics.html"><i class="fa fa-check"></i><b>5</b> Graphics</a><ul>
<li class="chapter" data-level="5.1" data-path="graphics.html"><a href="graphics.html#the-basics-of-r-graphics"><i class="fa fa-check"></i><b>5.1</b> The basics of R graphics</a></li>
<li class="chapter" data-level="5.2" data-path="graphics.html"><a href="graphics.html#x-y-plots"><i class="fa fa-check"></i><b>5.2</b> X-Y plots</a></li>
<li class="chapter" data-level="5.3" data-path="graphics.html"><a href="graphics.html#histograms"><i class="fa fa-check"></i><b>5.3</b> Histograms</a></li>
<li class="chapter" data-level="5.4" data-path="graphics.html"><a href="graphics.html#boxplots"><i class="fa fa-check"></i><b>5.4</b> Boxplots</a></li>
<li class="chapter" data-level="5.5" data-path="graphics.html"><a href="graphics.html#images-and-contour-plots"><i class="fa fa-check"></i><b>5.5</b> Images and contour plots</a></li>
<li class="chapter" data-level="5.6" data-path="graphics.html"><a href="graphics.html#plotting-a-mathematical-function"><i class="fa fa-check"></i><b>5.6</b> Plotting a mathematical function</a></li>
<li class="chapter" data-level="5.7" data-path="graphics.html"><a href="graphics.html#multiple-figures-in-one-graphical-device"><i class="fa fa-check"></i><b>5.7</b> Multiple figures in one graphical device</a></li>
<li class="chapter" data-level="5.8" data-path="graphics.html"><a href="graphics.html#saving-graphs"><i class="fa fa-check"></i><b>5.8</b> Saving graphs</a></li>
<li class="chapter" data-level="5.9" data-path="graphics.html"><a href="graphics.html#graphical-systems"><i class="fa fa-check"></i><b>5.9</b> Different graphical systems and packages</a></li>
<li class="chapter" data-level="5.10" data-path="graphics.html"><a href="graphics.html#exercises-1"><i class="fa fa-check"></i><b>5.10</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#simple-curves"><i class="fa fa-check"></i>Simple curves</a></li>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#human-population-growth"><i class="fa fa-check"></i>Human population growth</a></li>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#toxic-ammonia"><i class="fa fa-check"></i>Toxic ammonia</a></li>
<li class="chapter" data-level="" data-path="graphics.html"><a href="graphics.html#the-iris-data-set"><i class="fa fa-check"></i>The iris data set</a></li>
<li><a href="graphics.html#automatic-coercion-by-plot">Automatic coercion by <code>plot()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="file-io.html"><a href="file-io.html"><i class="fa fa-check"></i><b>6</b> File input and output</a><ul>
<li class="chapter" data-level="6.1" data-path="file-io.html"><a href="file-io.html#defining-the-path-to-a-file-or-directory"><i class="fa fa-check"></i><b>6.1</b> Defining the path to a file or directory</a></li>
<li class="chapter" data-level="6.2" data-path="file-io.html"><a href="file-io.html#the-working-directory"><i class="fa fa-check"></i><b>6.2</b> The “working directory”</a></li>
<li class="chapter" data-level="6.3" data-path="file-io.html"><a href="file-io.html#using-the-read.table-and-write.table-functions"><i class="fa fa-check"></i><b>6.3</b> Using the <code>read.table</code> and <code>write.table</code> functions</a></li>
<li class="chapter" data-level="6.4" data-path="file-io.html"><a href="file-io.html#reading-data-from-a-webserver"><i class="fa fa-check"></i><b>6.4</b> Reading data from a webserver</a></li>
<li class="chapter" data-level="6.5" data-path="file-io.html"><a href="file-io.html#reading-data-from-compressed-files-and-archives"><i class="fa fa-check"></i><b>6.5</b> Reading data from compressed files and archives</a></li>
<li class="chapter" data-level="6.6" data-path="file-io.html"><a href="file-io.html#inputoutput-with-excel-files-and-database-management-systems"><i class="fa fa-check"></i><b>6.6</b> Input/output with Excel files and database management systems</a></li>
<li class="chapter" data-level="6.7" data-path="file-io.html"><a href="file-io.html#exercises-2"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Programming-with-R.html"><a href="Programming-with-R.html"><i class="fa fa-check"></i><b>7</b> Programming with R</a><ul>
<li class="chapter" data-level="7.1" data-path="Programming-with-R.html"><a href="Programming-with-R.html#defining-a-function"><i class="fa fa-check"></i><b>7.1</b> Defining a function</a></li>
<li class="chapter" data-level="7.2" data-path="Programming-with-R.html"><a href="Programming-with-R.html#program-flow-control"><i class="fa fa-check"></i><b>7.2</b> Program flow control</a></li>
<li class="chapter" data-level="7.3" data-path="Programming-with-R.html"><a href="Programming-with-R.html#literature"><i class="fa fa-check"></i><b>7.3</b> Literature</a></li>
<li class="chapter" data-level="7.4" data-path="Programming-with-R.html"><a href="Programming-with-R.html#exercises-3"><i class="fa fa-check"></i><b>7.4</b> Exercises</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Programming-with-R.html"><a href="Programming-with-R.html#programming-loops"><i class="fa fa-check"></i><b>7.4.1</b> Loops</a></li>
<li class="chapter" data-level="" data-path="Programming-with-R.html"><a href="Programming-with-R.html#diversity-of-deep-sea-nematodes"><i class="fa fa-check"></i>Diversity of deep-sea nematodes</a></li>
<li class="chapter" data-level="" data-path="Programming-with-R.html"><a href="Programming-with-R.html#diversity-indices-a-function-optional"><i class="fa fa-check"></i>Diversity indices – a function (optional)</a></li>
<li class="chapter" data-level="" data-path="Programming-with-R.html"><a href="Programming-with-R.html#rarefaction-diversity-optional"><i class="fa fa-check"></i>Rarefaction diversity (optional)</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Programming-with-R.html"><a href="Programming-with-R.html#add-prog-ex"><i class="fa fa-check"></i><b>7.5</b> Additional programming exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="vectorization.html"><a href="vectorization.html"><i class="fa fa-check"></i><b>8</b> Vectorization</a><ul>
<li class="chapter" data-level="8.1" data-path="vectorization.html"><a href="vectorization.html#the-function-apply"><i class="fa fa-check"></i><b>8.1</b> The function <code>apply()</code></a></li>
<li class="chapter" data-level="8.2" data-path="vectorization.html"><a href="vectorization.html#the-function-tapply"><i class="fa fa-check"></i><b>8.2</b> The function <code id="the-function-tapply">tapply()</code></a></li>
<li class="chapter" data-level="8.3" data-path="vectorization.html"><a href="vectorization.html#the-functions-lapply-and-sapply"><i class="fa fa-check"></i><b>8.3</b> The functions <code>lapply()</code> and <code>sapply()</code></a></li>
<li class="chapter" data-level="8.4" data-path="vectorization.html"><a href="vectorization.html#exercises-4"><i class="fa fa-check"></i><b>8.4</b> Exercises</a><ul>
<li class="chapter" data-level="8.4.1" data-path="vectorization.html"><a href="vectorization.html#permutation-function"><i class="fa fa-check"></i><b>8.4.1</b> A permutation function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reshaping.html"><a href="reshaping.html"><i class="fa fa-check"></i><b>9</b> Reshaping and manipulating complex data</a><ul>
<li class="chapter" data-level="9.1" data-path="reshaping.html"><a href="reshaping.html#the-tidyr-package"><i class="fa fa-check"></i><b>9.1</b> The <code>tidyr</code> package</a></li>
<li class="chapter" data-level="9.2" data-path="reshaping.html"><a href="reshaping.html#the-dplyr-package"><i class="fa fa-check"></i><b>9.2</b> The <code>dplyr</code> package</a></li>
<li class="chapter" data-level="9.3" data-path="reshaping.html"><a href="reshaping.html#exercises-5"><i class="fa fa-check"></i><b>9.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="formulasyntax.html"><a href="formulasyntax.html"><i class="fa fa-check"></i><b>10</b> Using formula syntax</a><ul>
<li class="chapter" data-level="10.1" data-path="formulasyntax.html"><a href="formulasyntax.html#using-formula-syntax-in-plotting"><i class="fa fa-check"></i><b>10.1</b> Using formula syntax in plotting</a></li>
<li class="chapter" data-level="10.2" data-path="formulasyntax.html"><a href="formulasyntax.html#using-formula-syntax-in-model-definition"><i class="fa fa-check"></i><b>10.2</b> Using formula syntax in model definition</a><ul>
<li class="chapter" data-level="10.2.1" data-path="formulasyntax.html"><a href="formulasyntax.html#data-with-a-continuous-explanatory-variable"><i class="fa fa-check"></i><b>10.2.1</b> Data with a continuous explanatory variable</a></li>
<li class="chapter" data-level="10.2.2" data-path="formulasyntax.html"><a href="formulasyntax.html#data-with-two-discrete-explanatory-variables-factors"><i class="fa fa-check"></i><b>10.2.2</b> Data with two discrete explanatory variables (factors)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Applications</b></span></li>
<li class="chapter" data-level="11" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>11</b> The carnival of distributions</a><ul>
<li class="chapter" data-level="11.1" data-path="distributions.html"><a href="distributions.html#distribution-functions"><i class="fa fa-check"></i><b>11.1</b> Distribution functions</a></li>
<li class="chapter" data-level="11.2" data-path="distributions.html"><a href="distributions.html#distribution-functions-in-r"><i class="fa fa-check"></i><b>11.2</b> Distribution functions in R</a></li>
<li class="chapter" data-level="11.3" data-path="distributions.html"><a href="distributions.html#the-exponential-and-poisson-distributions"><i class="fa fa-check"></i><b>11.3</b> The exponential and Poisson distributions</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercises-6"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="distributions.html"><a href="distributions.html#the-bernoulli-and-binomial-distributions"><i class="fa fa-check"></i><b>11.4</b> The Bernoulli and binomial distributions</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercises-7"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="distributions.html"><a href="distributions.html#the-normal-and-standard-normal-distribution"><i class="fa fa-check"></i><b>11.5</b> The normal and standard normal distribution</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="distributions.html"><a href="distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>11.6</b> Student’s t-distribution</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="distributions.html"><a href="distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i><b>11.7</b> The chi-squared distribution</a><ul>
<li class="chapter" data-level="11.7.1" data-path="distributions.html"><a href="distributions.html#application-in-pearsons-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>11.7.1</b> Application in Pearson’s chi-square goodness of fit test</a></li>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="distributions.html"><a href="distributions.html#the-f-distribution"><i class="fa fa-check"></i><b>11.8</b> The F-distribution</a><ul>
<li class="chapter" data-level="11.8.1" data-path="distributions.html"><a href="distributions.html#analysis-of-variance"><i class="fa fa-check"></i><b>11.8.1</b> Analysis of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="linearmodels.html"><a href="linearmodels.html"><i class="fa fa-check"></i><b>12</b> Linear models and ANOVA</a><ul>
<li class="chapter" data-level="12.1" data-path="linearmodels.html"><a href="linearmodels.html#modeling-with-factor-type-predictor-variables"><i class="fa fa-check"></i><b>12.1</b> Modeling with factor-type predictor variables</a><ul>
<li class="chapter" data-level="12.1.1" data-path="linearmodels.html"><a href="linearmodels.html#alternative-dummy-variable-coding-schemes"><i class="fa fa-check"></i><b>12.1.1</b> Alternative dummy variable coding schemes</a></li>
<li class="chapter" data-level="" data-path="linearmodels.html"><a href="linearmodels.html#exercises-8"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="linearmodels.html"><a href="linearmodels.html#two-way-anovafactorial-anova"><i class="fa fa-check"></i><b>12.2</b> Two-way ANOVA/factorial ANOVA</a><ul>
<li class="chapter" data-level="12.2.1" data-path="linearmodels.html"><a href="linearmodels.html#unbalanced-data"><i class="fa fa-check"></i><b>12.2.1</b> Unbalanced data</a></li>
<li class="chapter" data-level="" data-path="linearmodels.html"><a href="linearmodels.html#exercise-5"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="linearmodels.html"><a href="linearmodels.html#combinations-of-numerical-and-discrete-predictors"><i class="fa fa-check"></i><b>12.3</b> Combinations of numerical and discrete predictors</a><ul>
<li class="chapter" data-level="" data-path="linearmodels.html"><a href="linearmodels.html#exercises-9"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="linearmodels.html"><a href="linearmodels.html#the-connection-between-linear-models-and-anova"><i class="fa fa-check"></i><b>12.4</b> The connection between linear models and ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hubble.html"><a href="hubble.html"><i class="fa fa-check"></i><b>13</b> The age of the universe</a><ul>
<li class="chapter" data-level="13.1" data-path="hubble.html"><a href="hubble.html#exercises-10"><i class="fa fa-check"></i><b>13.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="datafabrication.html"><a href="datafabrication.html"><i class="fa fa-check"></i><b>14</b> A case of data fabrication</a><ul>
<li class="chapter" data-level="14.1" data-path="datafabrication.html"><a href="datafabrication.html#exercises-11"><i class="fa fa-check"></i><b>14.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="amt-carrier.html"><a href="amt-carrier.html"><i class="fa fa-check"></i><b>15</b> A critical evaluation of ammonium transporter kinetics</a><ul>
<li class="chapter" data-level="15.1" data-path="amt-carrier.html"><a href="amt-carrier.html#exercises-12"><i class="fa fa-check"></i><b>15.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="bias-metabolomics.html"><a href="bias-metabolomics.html"><i class="fa fa-check"></i><b>16</b> Bias in metabolomics data</a><ul>
<li class="chapter" data-level="16.1" data-path="bias-metabolomics.html"><a href="bias-metabolomics.html#exercises-13"><i class="fa fa-check"></i><b>16.1</b> Exercises</a><ul>
<li class="chapter" data-level="16.1.1" data-path="bias-metabolomics.html"><a href="bias-metabolomics.html#an-alternative-solution-generalized-additive-modeling-optional"><i class="fa fa-check"></i><b>16.1.1</b> An alternative solution: Generalized additive modeling (optional)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nerve-fiber.html"><a href="nerve-fiber.html"><i class="fa fa-check"></i><b>17</b> Correlation between fiber density and episodic memory?</a><ul>
<li class="chapter" data-level="17.1" data-path="nerve-fiber.html"><a href="nerve-fiber.html#exercises-14"><i class="fa fa-check"></i><b>17.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="classifiers.html"><a href="classifiers.html"><i class="fa fa-check"></i><b>18</b> Logistic regression</a><ul>
<li class="chapter" data-level="18.1" data-path="classifiers.html"><a href="classifiers.html#classifiers"><i class="fa fa-check"></i><b>18.1</b> Classifiers</a></li>
<li class="chapter" data-level="18.2" data-path="classifiers.html"><a href="classifiers.html#logistic-regression"><i class="fa fa-check"></i><b>18.2</b> Logistic regression</a><ul>
<li class="chapter" data-level="18.2.1" data-path="classifiers.html"><a href="classifiers.html#logistic-regression-a-case-of-generalized-linear-modeling"><i class="fa fa-check"></i><b>18.2.1</b> Logistic Regression: a case of Generalized Linear Modeling</a></li>
<li class="chapter" data-level="18.2.2" data-path="classifiers.html"><a href="classifiers.html#logistic-regression-in-r"><i class="fa fa-check"></i><b>18.2.2</b> Logistic regression in R</a></li>
<li class="chapter" data-level="18.2.3" data-path="classifiers.html"><a href="classifiers.html#exercises-15"><i class="fa fa-check"></i><b>18.2.3</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html"><i class="fa fa-check"></i><b>19</b> Classification of dairy bacteria</a><ul>
<li class="chapter" data-level="19.1" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#exercises-16"><i class="fa fa-check"></i><b>19.1</b> Exercises</a><ul>
<li class="chapter" data-level="19.1.1" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#description-of-the-data"><i class="fa fa-check"></i><b>19.1.1</b> Description of the data</a></li>
<li class="chapter" data-level="19.1.2" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#data-conversion"><i class="fa fa-check"></i><b>19.1.2</b> Data conversion</a></li>
<li class="chapter" data-level="19.1.3" data-path="class-dairy-strains.html"><a href="class-dairy-strains.html#data-analysis"><i class="fa fa-check"></i><b>19.1.3</b> Data analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="naivebayes.html"><a href="naivebayes.html"><i class="fa fa-check"></i><b>20</b> Naïve Bayes classifiers</a><ul>
<li class="chapter" data-level="20.1" data-path="naivebayes.html"><a href="naivebayes.html#the-naive-bayes-classifier"><i class="fa fa-check"></i><b>20.1</b> The Naive Bayes classifier</a></li>
<li class="chapter" data-level="20.2" data-path="naivebayes.html"><a href="naivebayes.html#a-crime-scene"><i class="fa fa-check"></i><b>20.2</b> A crime scene</a></li>
<li class="chapter" data-level="20.3" data-path="naivebayes.html"><a href="naivebayes.html#reconstructing-bayes-lawtheorem"><i class="fa fa-check"></i><b>20.3</b> Reconstructing Bayes law/theorem</a></li>
<li class="chapter" data-level="20.4" data-path="naivebayes.html"><a href="naivebayes.html#deciding-on-the-class"><i class="fa fa-check"></i><b>20.4</b> Deciding on the class</a></li>
<li class="chapter" data-level="20.5" data-path="naivebayes.html"><a href="naivebayes.html#continuous-predicting-variables"><i class="fa fa-check"></i><b>20.5</b> Continuous predicting variables</a></li>
<li class="chapter" data-level="20.6" data-path="naivebayes.html"><a href="naivebayes.html#combining-information-from-different-predictor-variables"><i class="fa fa-check"></i><b>20.6</b> Combining information from different predictor variables</a></li>
<li class="chapter" data-level="20.7" data-path="naivebayes.html"><a href="naivebayes.html#exercises-17"><i class="fa fa-check"></i><b>20.7</b> Exercises</a><ul>
<li class="chapter" data-level="20.7.1" data-path="naivebayes.html"><a href="naivebayes.html#predicting-iris-species"><i class="fa fa-check"></i><b>20.7.1</b> Predicting iris species</a></li>
<li class="chapter" data-level="20.7.2" data-path="naivebayes.html"><a href="naivebayes.html#predicting-income"><i class="fa fa-check"></i><b>20.7.2</b> Predicting income</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="resampling-techniques.html"><a href="resampling-techniques.html"><i class="fa fa-check"></i><b>21</b> Resampling techniques</a><ul>
<li class="chapter" data-level="21.1" data-path="resampling-techniques.html"><a href="resampling-techniques.html#bootstrapping"><i class="fa fa-check"></i><b>21.1</b> Bootstrapping</a></li>
<li class="chapter" data-level="21.2" data-path="resampling-techniques.html"><a href="resampling-techniques.html#exercises-18"><i class="fa fa-check"></i><b>21.2</b> Exercises</a><ul>
<li class="chapter" data-level="21.2.1" data-path="resampling-techniques.html"><a href="resampling-techniques.html#medical-patches"><i class="fa fa-check"></i><b>21.2.1</b> Medical patches</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="resampling-techniques.html"><a href="resampling-techniques.html#permutation-test"><i class="fa fa-check"></i><b>21.3</b> Permutation test</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html"><i class="fa fa-check"></i><b>22</b> Numerical differentiation and smoothing</a><ul>
<li class="chapter" data-level="22.1" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html#exercises-19"><i class="fa fa-check"></i><b>22.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="randomnumbers.html"><a href="randomnumbers.html"><i class="fa fa-check"></i><b>23</b> Random numbers</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linearmodels" class="section level1">
<h1><span class="header-section-number">CHAPTER 12</span> Linear models and ANOVA</h1>
<div class="rmdtip">
<p>
This subject is very large, and this chapter can only give a brief introduction. Much more can be found in for example the book by <span class="citation"><span class="citation">Faraway (<a href="#ref-Faraway2005">2005</a>)</span></span>. I would also like to recommend a very good introductory book “An introduction to statistical learning” by <span class="citation"><span class="citation">James et al. (<a href="#ref-James2013">2013</a>)</span></span>. You can obtain the pdf-file of this book for free on the author’s website: <a href="http://www-bcf.usc.edu/~gareth/ISL" class="uri">http://www-bcf.usc.edu/~gareth/ISL</a>. A number of the techniques that are used in this syllabus are discussed extensively and in very clear language in this book. Use it! The book is accompanied by an enlightening <a href="https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/">series of weblectures</a> by three of the authors. If you are interested in data analysis, spending 15 hours on these lectures are well worth the investment.
</p>
</div>
<p>In general, a statistical model is a function of some predictor variables <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, <span class="math inline">\(\ldots\)</span> used to fit measurements of a response variable <span class="math inline">\(y\)</span>. The data used to fit the model is called “training data”. The goal of a statistical model is not to fit the training data as well as possible, but to find a function of the predictor variables, that predicts <strong>new data</strong> as accurately as possible. By new data we mean data that have not been used to construct the model, <em>i.e.</em> that are not in the training data. When using this criterion one often concludes that some or many of the predictor variables need to be discarded from the fitting function, and that the complexity of the function should not be very high. This apparent paradox can be understood from the fact that a complex function of many variables will not only fit an underlying relation between response and predictor variables, but will also fit measurement noise. When a model becomes so complex that it starts to fit noise in the training data then its predictive capacity will deteriorate. More on this subject can be found in chapter 2.1 (“What is statistical learning?”) of <span class="citation">James et al. (<a href="#ref-James2013">2013</a>)</span>.</p>
<p>Linear models use a particular class of functions to fit data, namely those functions in which the parameters <span class="math inline">\(\beta_i\)</span> to be fitted occur in a linear fashion. This means that the exponents of the <span class="math inline">\(\beta_i\)</span> are equal to 1. The predictor variables can be present in the function in a linear or non-linear fashion. The most generic way to describe a function used for linear modeling is:</p>
<p><span class="math display">\[
y = \beta_0 + \sum \beta_i \phi_i(x_1, \ldots x_n)
\]</span></p>
<p>where the functions <span class="math inline">\(\phi_i(x_1, \ldots x_n)\)</span> can be linear or non-linear functions, but they are functions of the predictor variables only. They do not contain parameters to be fitted. An example is <span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 
\]</span> or an other <span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1^2 
\]</span> Data sets to be modeled consist of <span class="math inline">\(m\)</span>-tuples <span class="math inline">\((y_j,x_{1j},\ldots,x_{nj}) \; \text{where} \; j=1 \ldots m\)</span>), each measurement represented by one tuple. In general, selecting a good model (“model selection”) from among several functions <span class="math inline">\(f(\beta_0,\ldots,\beta_k,x_1,\ldots,x_n)\)</span> consists of two parts:</p>
<ol style="list-style-type: decimal">
<li>Fitting of the functions. This entails finding the combination of values for <span class="math inline">\(\beta_0,\ldots,\beta_k\)</span> that minimizes the sum of squares <span class="math display">\[
\sum_{j=1}^m \left ( y_j - f(\beta_0,\ldots,\beta_k,x_1,\ldots,x_n) \right )^2
\]</span></li>
<li>Discarding terms of a well fitting function <span class="math inline">\(f\)</span> that do not contribute to modeling the underlying relation between the response and predictor variables. In practice, this could mean that a variable is entirely left out of the function, or that higher order terms, like <span class="math inline">\(x_1^2\)</span> or <span class="math inline">\(x_1 x_2\)</span> are left out (equivalently, their coefficients can be set to 0). ANOVA is one of the techniques to identify these terms, as I will explain.</li>
</ol>
<p>Although apparently somewhat restricted in their flexibility, linear models are an important and versatile type of model which is used a lot in modern statistics. One reason is that the predictor variables <span class="math inline">\(x_i\)</span> of linear models can be both numerical variables as well as discrete, factor-type variables. Functions with mixtures of both are also allowed. Another is that the terms and coefficients are relatively easy to interpret. Any type of linear model, whether having only factor-type predictor variables, continuous variables or mixtures of these, can be fitted in R using the function <code>lm()</code>. The appropriateness of the fits, <em>i.e.</em> the “significance” of predictive terms can then be analysed (the second phase of model selection) using the <code>anova()</code> function. Lastly, it is relatively easy to obtain confidence intervals for the estimated parameters.</p>
<div id="modeling-with-factor-type-predictor-variables" class="section level2">
<h2><span class="header-section-number">12.1</span> Modeling with factor-type predictor variables</h2>
<p>To be able to use the same framework for continuous as well as factor variables, the latter are transformed into so-called “dummy” variables having discrete numerical values that correspond to the levels of a factor variable. To illustrate this, suppose that we have measured the weight <span class="math inline">\(y\)</span> of a sample of males and females from a population, and want to predict the weight using the gender variable <span class="math inline">\(x\)</span>. Or we simply want to know whether the weight of males and females differs significantly. Clearly, <span class="math inline">\(x\)</span> is a factor variable with two levels, ‘F’ and ‘M’. We can transform <span class="math inline">\(x\)</span> into a dummy variable <span class="math inline">\(x&#39;\)</span> having numerical levels 0 and 1, corresponding to the levels ‘F’ and ‘M’, respectively. Then we can make a plot of the weight measurements as a function of <span class="math inline">\(x&#39;\)</span> and calculate the best-fitting straight line through it:</p>
<div class="figure"><span id="fig:lm01"></span>
<img src="StatR_files/figure-html/lm01-1.png" alt="Weight as a function of gender. The gender variable was converted to a numeric dummy variable. The line is a least-squares fit through the data. The data were sampled from a US population that frequented health and fitness clubs." width="672" />
<p class="caption">
Figure 12.1: Weight as a function of gender. The gender variable was converted to a numeric dummy variable. The line is a least-squares fit through the data. The data were sampled from a US population that frequented health and fitness clubs.
</p>
</div>
<p>The fitted line has the equation</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 x&#39;
\]</span></p>
<p>The interpretation of the coefficients is as follows:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>, or the intercept, is the average weight of females</li>
<li><span class="math inline">\(\beta_1\)</span>, or the slope, is the <em>difference</em> between the average weight of males and females, since it is the increase of the fitted line <em>over a unit interval</em>. The fit can be performed with the <code>lm()</code> function which creates the dummy variable behind the scenes to calculate the coefficients. Creating the fit (the “model”) and querying its coefficients is easy:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(weight<span class="op">~</span>gender, d)
<span class="kw">coefficients</span>(model)</code></pre></div>
<pre><code>## (Intercept)     genderM 
##    63.73333    16.78333</code></pre>
<p>This tells us that the average weight of women is 63.7 kg and that the difference between the average weights of males and females is 16.8 kg. In the terminology of linear modeling, such a difference is called a <strong>contrast</strong>.</p>
<p>Now we can ask three questions which are fully equivalent:</p>
<ol style="list-style-type: decimal">
<li>Is the slope <span class="math inline">\(\beta_1\)</span> significantly different from 0?</li>
<li>Does gender predict body weight?</li>
<li>Is the weight of men and women significantly different?</li>
</ol>
<p>All three are answered at the same time by an ANOVA of the fit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(model)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: weight
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## gender     1 1690.1 1690.08  18.033 0.0003304 ***
## Residuals 22 2061.8   93.72                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA shows that the variable <span class="math inline">\(x\)</span> (gender) leads to a sigificant reduction in the residual sum of squares, as indicated by the F-statistic and corresponding p-value (<em>Pr(&gt;F)</em>) of the F-test (see Chapter <a href="distributions.html#distributions">11</a> on the F-distribution). Another way to obtain the same (and more) information is by applying the <code>summary()</code> method on the <code>lm</code> object</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ gender, data = d)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.733  -8.633   0.875   5.883  19.267 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   63.733      2.795  22.806  &lt; 2e-16 ***
## genderM       16.783      3.952   4.247  0.00033 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.681 on 22 degrees of freedom
## Multiple R-squared:  0.4505, Adjusted R-squared:  0.4255 
## F-statistic: 18.03 on 1 and 22 DF,  p-value: 0.0003304</code></pre>
<p>The <code>summary()</code> method not only shows the F-statistic, but also the t-statistics of the individual coefficients (<em>i.e.</em> how many times their standard error they differ from 0). This information can be used to judge the predictive contribution of individual coefficients, rather than predictor variables. This is particularly relevant if there are more than two levels in a factor-type predictor variable.</p>
<p>How are factor variables translated to dummy variables if they contain more than two levels? Just by adding a dummy variable that can assume values 0 or 1. The coding scheme is worked out below for a factor variable <span class="math inline">\(x\)</span> with three levels A, B and C, which is transformed into two numerical dummy variables <span class="math inline">\(x&#39;\)</span> and <span class="math inline">\(x&#39;&#39;\)</span></p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center"><span class="math inline">\(x&#39;\)</span></th>
<th align="center"><span class="math inline">\(x&#39;&#39;\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Suppose that B and C represent two different fertilization strategies of crops, and that the response variable <span class="math inline">\(y\)</span> is the crop yield, where A is the control treatment without fertilizer. The model equation now contains two variables and three coefficients:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 x&#39; + \beta_2 x&#39;&#39;
\]</span> The fit can be interpreted as a plane through the points above each of the corners of a plane defined by the axes <span class="math inline">\(x&#39;\)</span> and <span class="math inline">\(x&#39;&#39;\)</span></p>
<div class="figure"><span id="fig:lm05"></span>
<img src="StatR_files/figure-html/lm05-1.png" alt="A model fit on a variable with three levels. We use two dummy predictor variables to represent the levels as the vectors (0,0):A, (1,0):B, and (0,1):C. The response variable, y, is presented as the third dimension, perpendiclar to these two vectors. A model fit can be represented as a plane fitted through the data points." width="672" />
<p class="caption">
Figure 12.2: A model fit on a variable with three levels. We use two dummy predictor variables to represent the levels as the vectors (0,0):A, (1,0):B, and (0,1):C. The response variable, y, is presented as the third dimension, perpendiclar to these two vectors. A model fit can be represented as a plane fitted through the data points.
</p>
</div>
<p>Due to the way that the dummy variables were coded (table above) the interpretation of the variables is as follows:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>, or the intercept is the average yield on treatment A, the control</li>
<li><span class="math inline">\(\beta_1\)</span>, or the slope of the plane in the direction of the <span class="math inline">\(x&#39;\)</span>-axis is the <em>difference</em> between the average yield of treatment B and the control</li>
<li><span class="math inline">\(\beta_2\)</span>, or the slope of the plane in the direction of the <span class="math inline">\(x&#39;&#39;\)</span>-axis is the <em>difference</em> between the average yield of treatment C and the control</li>
</ul>
<p>So, the <em>contrasts</em> comprise comparisons between fertilizers and the control. The fit can again be performed with the <code>lm()</code> function which again implicitly performs the translation into the dummy variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data=</span>d)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = d)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.459  -9.393   1.661   5.542  22.263 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   66.953      4.807  13.928 9.05e-09 ***
## xB            53.723      6.798   7.902 4.26e-06 ***
## xC            71.104      6.798  10.459 2.20e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 10.75 on 12 degrees of freedom
## Multiple R-squared:  0.9083, Adjusted R-squared:  0.8931 
## F-statistic: 59.46 on 2 and 12 DF,  p-value: 5.932e-07</code></pre>
<p>And performing an ANOVA on the fit yields:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(model)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## x          2 13740.0  6870.0  59.457 5.932e-07 ***
## Residuals 12  1386.6   115.5                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>So, yes from the ANOVA we conclude that the variable ‘fertilizer treatment’ does have predictive value for the crop yield. The t-statistic and corresponding p-values of the parameters <code>xB</code> and <code>xC</code> suggest that both fertilizers give a higher croip yield.</p>
<div class="rmdnote">
<p>
Note that when concluding that a multi-valued factor has an effect, we would usually perform a <em>Tukey honest siginificant difference</em> test, or multiple <em>t-tests</em> on the individual levels compared to the control with multiple-testing correction on the p-values to make a fair comparison. However, the <code>summary()</code> method gives a good indication of the significance of the individual coefficients.
</p>
</div>
<div id="alternative-dummy-variable-coding-schemes" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Alternative dummy variable coding schemes</h3>
<p>Sometimes, an alternative dummy-variable coding scheme is desirable because you are interested in different contrasts. One desired change of coding scheme is often that you would like a different level of a factor variable to be the ofset of the fit. This can be easily achieved. By default, the level represented by the number 1 (remember, factor-vectors are a child class of integer-type vectors) is chosen as the origin for the fit. To change this level, you can use the function <code>relevel()</code> to convert the original factor to one with the desired level at first position.</p>
<p>Other dummy coding schemes can be achieved by supplying the <code>contrasts</code> argument of the <code>lm()</code> function with a contrast matrix. Alternatively, many standard coding schemes can be called by using alternative formulations of the model formula.</p>
<p>For example, suppose your lab has measured crop yield under reference conditions extremely often and has a very accurate value for the control yield. Then you might decide to report <span class="math inline">\(y\)</span> as the <em>yield difference</em> between plants treated with fertilizers A or B and that default control yield. What you would then need is a coding scheme that looks like this:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center"><span class="math inline">\(x&#39;\)</span></th>
<th align="center"><span class="math inline">\(x&#39;&#39;\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>In other words: all of the treatments are compared to yield difference = 0. The easiest way to achieve this coding or contrast scheme is to use the modeling formula <code>y ~ 0 + x</code> (instead of <code>y ~ x</code>) in the <code>lm()</code> call. This indicates to the <code>lm()</code> function that it should not fit an offset, or equivalently that it should force the fitted plane to go through <span class="math inline">\(y=0\)</span> at the origin.</p>
<p>Another contrast scheme would be the one used in Chapter <a href="distributions.html#distributions">11</a>, where yields in the fertilization groups are compared to the average yield. The corresponding dummy variable scheme for an experiment with two fertilizer treatments A and B would be (note that this is the scheme used by a t-test)</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center"><span class="math inline">\(x&#39;\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">-1</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
</div>
<div id="exercises-8" class="section level3 unnumbered">
<h3>Exercises</h3>
<ol style="list-style-type: decimal">
<li>Proper balancing in experimental design is necessary to obtain reliable results from an ANOVA. By this we mean that all levels in a factor predictor variable (or combinations of levels in case of multiple factor predictors) should be represented by approximately equal numbers of data points. Deduce from figures <a href="linearmodels.html#fig:lm01">12.1</a> and <a href="linearmodels.html#fig:lm05">12.2</a> why that is desirable.
<div>
<a id="LinearmodelsHead1" href="javascript:toggle('LinearmodelsSol1','LinearmodelsHead1');" >Show solution</a>
</div>
<div id="LinearmodelsSol1" style="display: none">
<p>The figures show that the effects are fits of lines planes or hyperplanes throught the data. If one of the levels would be underrepresented relative to another then that would mean that the slopes of these planes would be determined by different numbers of points. In an extreme case, a slope might be determined by many points in one level and only one in another. Having equal numbers of points would make the estimates of the slopes more accurate.</p>
</div></li>
</ol>
<div class="rmdnote">
<p>
Note that we speak of an <em>experimental design</em> with unbalanced data. However, in many cases it is not a matter of design, but of availability of data. If you do have control over the number of data points per combination of factor-levels, then balancing these is important. Below I discuss another effect of unbalanced data in the context of data with two factor-type predictor variables.
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Suppose you want to answer the question whether fertilizers B and C have a significant, but also the same effect on crop yield. To answer this question, you need a dummy variable scheme that differs from the one used in figure <a href="linearmodels.html#fig:lm05">12.2</a>. Which scheme do you need? Use figure <a href="linearmodels.html#fig:lm05">12.2</a> to ask where you should put the points for level C in order to answer that question and then define the corresponding dummy variables. Notice that you should test whether the difference between the levels A and either B or C is significant, but that at the same time that between B and C equals 0.
<div>
<a id="LinearmodelsHead2" href="javascript:toggle('LinearmodelsSol2','LinearmodelsHead2');" >Show solution</a>
</div>
<div id="LinearmodelsSol2" style="display: none">
<p>If you would place the points of level C at (1,1), then the slope in the direction of (0,1) would represent the difference ‘C - B’. Although not part of the question, we show how the fit can be carried out by filling in the <code>contrasts</code> argument of the <code>lm()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">contrast.matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)
<span class="kw">rownames</span>(contrast.matrix) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;A&#39;</span>,<span class="st">&#39;B&#39;</span>,<span class="st">&#39;C&#39;</span>)
<span class="kw">colnames</span>(contrast.matrix) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;B - A&#39;</span>, <span class="st">&#39;C - B&#39;</span>)
contrast.matrix</code></pre></div>
<pre><code>##   B - A C - B
## A     0     0
## B     1     0
## C     1     1</code></pre>
<p>Then use this contrast matrix in the linear modeling function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.alt.contr =<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data=</span>d, <span class="dt">contrasts =</span> <span class="kw">list</span>(<span class="dt">x=</span>contrast.matrix))
<span class="kw">summary</span>(model.alt.contr)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = d, contrasts = list(x = contrast.matrix))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.459  -9.393   1.661   5.542  22.263 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   66.953      4.807  13.928 9.05e-09 ***
## xB - A        53.723      6.798   7.902 4.26e-06 ***
## xC - B        17.381      6.798   2.557   0.0252 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 10.75 on 12 degrees of freedom
## Multiple R-squared:  0.9083, Adjusted R-squared:  0.8931 
## F-statistic: 59.46 on 2 and 12 DF,  p-value: 5.932e-07</code></pre>
<p>The summary shows that the difference ‘B - C’ that we have encoded in the contrast matrix is only just significant at 0.05 level according to its t-statistic.</p>
</div></li>
</ol>
</div>
</div>
<div id="two-way-anovafactorial-anova" class="section level2">
<h2><span class="header-section-number">12.2</span> Two-way ANOVA/factorial ANOVA</h2>
<p>The ANOVA’s shown in the previous examples were all one-way ANOVA’s because they concerned models with a single (factor-type) predictor variable. When models with two or more factor-type predictor variables are investigated using ANOVA, this is called two-way ANOVA in case of two predictor variables or factorial ANOVA in case of two or more predictor variables. There is, apart from the number of predictor variables used, no fundamental difference between one-, two-way and factorial ANOVA.</p>
<p>Linear models of two or more factor variables clearly require more complex dummy encoding schemes, but the principle of dummy encoding does not differ fundamentally from that discussed above. An example of a two-way ANOVA and corresponding models is taken from the analysis of plasmid transformation in the industrially important microorganism <em>Corynebacterium glutamicum</em>. Plasmid transformation is an essential experimental technique used to make mutants of an organism. The efficiency of the transformation procedure was investigated under two experimental variations: growth of cells at low or room temperature (“growth temperature treatment”, variable name <span class="math inline">\(t\)</span>) and the application of a heat shock or not to the cells just after the transformation (“heat shock treatment”, variable name <span class="math inline">\(h\)</span>). The data are from <span class="citation">Rest, Lange, and Molenaar (<a href="#ref-Rest1999">1999</a>)</span>. Having two levels in each variable, there are four possible combinations of both treatments. A plot of the data is shown below.</p>
<div class="rmdnote">
<p>
Due to the way the counts were obtained, the plasmid transformation count data had a proportional error. This implies that the standard deviation <span class="math inline"><span class="math inline">\(\sigma\)</span></span> of the count data is a fixed percentage of the counts obtained. This is a problem when applying ANOVA, because the underlying assumption for the F-test is that the error terms were all sampled from a single distribution with a single constant <span class="math inline"><span class="math inline">\(\sigma\)</span></span>. In the count data, the <span class="math inline"><span class="math inline">\(\sigma\)</span></span> increases with the count value itself. Fortunately, this defect in the data can be repaired by taking the logarithm of the original count values as a new response variable. This logarithmic transformation yields a variable with a constant error. Since many experimental data have proportional error, you will find that the logarithmic transform is often applied. See for example the Wiki page on <a href="https://en.wikipedia.org/wiki/Variance-stabilizing_transformation">variance-stabilizing transformations</a>.
</p>
</div>
<p><img src="StatR_files/figure-html/lm08-1.png" width="672" /></p>
<p>The first model is to assume that the effect of both treatments is additive (on the logarithmic scale. This means it would be multiplicative on the original plasmid transformation scale.) The formula used for this model is <code>log.transforms ~ t + h</code>. The corresponding mathematical formulation of the fitting function would look like:</p>
<span class="math display" id="eq:transform-additive">\[\begin{equation}
y = \beta_0 + \beta_1 t + \beta_2 h\tag{12.1}
\end{equation}\]</span>
<p>which has three parameters, <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>. Since <span class="math inline">\(t\)</span> and <span class="math inline">\(h\)</span> are (modified to) dummy variables they can only assume the values 0 (no normal growth temperature or no heat shock) or 1 (low growth temperature or with heat shock). When fitting eq <a href="linearmodels.html#eq:transform-additive">(12.1)</a> we effectively fit the following equations in one calculation:</p>
<span class="math display">\[\begin{equation*}
   y = 
\begin{cases}
  \beta_0 &amp; \text{if } t = 0 \text{,}\; h = 0 \\
  \beta_0 + \beta_1 &amp; \text{if } t = 1 \text{,}\; h = 0 \\
  \beta_0 + \beta_2 &amp; \text{if } t = 0 \text{,}\; h = 1 \\
  \beta_0 + \beta_1 + \beta_2 &amp; \text{if } t = 1 \text{,}\; h = 1 
\end{cases}
\end{equation*}\]</span>
<p>After fitting wit <code>lm()</code>, a summary of the additive model is given:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.additive &lt;-<span class="st"> </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>t <span class="op">+</span><span class="st"> </span>h, <span class="dt">data=</span>transforms.x)
<span class="kw">summary</span>(model.additive)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log.transforms ~ t + h, data = transforms.x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.52647 -0.31871  0.00312  0.30079  0.54141 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.9500     0.1682  11.596 3.15e-08 ***
## tlow          1.6346     0.1942   8.418 1.27e-06 ***
## hshock        2.2720     0.1942  11.701 2.83e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3884 on 13 degrees of freedom
## Multiple R-squared:  0.9411, Adjusted R-squared:  0.9321 
## F-statistic: 103.9 on 2 and 13 DF,  p-value: 1.012e-08</code></pre>
<p>The summary shows that all coefficients have high t-statistics. From the figure, it could be concluded that the combined effect of growth at low temperature and application of a heat shock is more than the effects of both treatments added together. Whether this is the case can be investihgated by comparintg this mode with one that includes a so-called <em>interaction effect</em>. The model formula that includes interaction effects as well as additive effects is <code>log.transforms ~ t * h</code>. It is equivalent to the formula <code>log.transforms ~ t + h + t:h</code>, that explicitly incorporates the interaction by the term <code>t:h</code>. The corresponding mathematical formulation of the fitting function would look like:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 t + \beta_2 h + \beta_3 t h 
\]</span></p>
<p>which has four parameters! You can see that <span class="math inline">\(\beta_3\)</span> is only added when both <span class="math inline">\(t\)</span> and <span class="math inline">\(h\)</span> are equal to 1, <em>i.e.</em> when cells were grown at low temperature and a heat shock was applied. This leads to the following effective fitting scheme:</p>
<span class="math display">\[\begin{equation*}
   y = 
\begin{cases}
    \beta_0 &amp; \text{if } t = 0 \text{,}\; h = 0 \\
    \beta_0 + \beta_1 &amp; \text{if } t = 1 \text{,}\; h = 0 \\
    \beta_0 + \beta_2 &amp; \text{if } t = 0 \text{,}\; h = 1 \\
    \beta_0 + \beta_1 + \beta_2 + \beta_3 &amp; \text{if } t = 1 \text{,}\; h = 1
\end{cases}
\end{equation*}\]</span>
<p>This model gives the following result.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>t <span class="op">*</span><span class="st"> </span>h, <span class="dt">data=</span>transforms.x)
<span class="kw">summary</span>(model.interaction)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log.transforms ~ t * h, data = transforms.x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.20294 -0.12456 -0.01459  0.12891  0.21787 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.27349    0.07717  29.459 1.46e-12 ***
## tlow         0.98757    0.10914   9.049 1.04e-06 ***
## hshock       1.62494    0.10914  14.889 4.23e-09 ***
## tlow:hshock  1.29413    0.15435   8.385 2.32e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1543 on 12 degrees of freedom
## Multiple R-squared:  0.9914, Adjusted R-squared:  0.9893 
## F-statistic: 461.9 on 3 and 12 DF,  p-value: 1.17e-12</code></pre>
<p>The t-statistic of the interaction effect is high (consequently, it has a low p-value of <span class="math inline">\(2.3\times 10^{-6}\)</span>), which indicates that incorporating it could have improved the fit. To be sure, we can compare the residual sums of squares of the two models using the <code>anova()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(model.additive, model.interaction)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: log.transforms ~ t + h
## Model 2: log.transforms ~ t * h
##   Res.Df     RSS Df Sum of Sq    F    Pr(&gt;F)    
## 1     13 1.96064                                
## 2     12 0.28588  1    1.6748 70.3 2.318e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>which shows that the incorporation of the interaction term makes the fit significantly better. We can conclude that there is a synergistic effect of the treatments, having a size of approximately 1.29 on the <span class="math inline">\(\text{log}_{10}\)</span> scale, or a <strong>factor</strong> 19.7 on the original count scale.</p>
<p>Finally, we plot the fits of the two models together with the data. Clearly, ‘fit’ here means a single number for each of the combinations of factor levels. Note that since the interaction model has four parameters, its predicted 10log(transformed cells) levels equal just the averages of the measurements at each of the four combinations.</p>
<div class="figure"><span id="fig:lm09c"></span>
<img src="StatR_files/figure-html/lm09c-1.png" alt="Predictions or fits by the additive model (red) and the model with interaction (blue)" width="672" />
<p class="caption">
Figure 12.3: Predictions or fits by the additive model (red) and the model with interaction (blue)
</p>
</div>
<div id="unbalanced-data" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Unbalanced data</h3>
<p>Unbalancedness of data can influence the outcome of an ANOVA for another reason than the one discussed above in an exercise. In a <em>hypothetical</em> firm a sample of the salaries of men and women were obtained (the example is from <span class="citation">Zahn (<a href="#ref-Zahn2010">2010</a>)</span>, and the data are available in <a href="data/linearmodels">data/linearmodels</a>). They are displayed in figure <a href="linearmodels.html#fig:sal02">12.4</a>. The linear model fit (in this case just the averages of salaries of men and women) shows that there is a slight difference of 0.23 thousand Euro. The difference is not significant: an ANOVA (or t-test) yields a p-value of 0.89. The conclusion from these data could be that there is no gender bias in salary, in this firm.</p>
<div class="figure"><span id="fig:sal02"></span>
<img src="StatR_files/figure-html/sal02-1.png" alt="Salaries of men and women in a hypothetical firm in thousand Euro. The line is a linear model (`salary ~ gender`) fitted to the data." width="672" />
<p class="caption">
Figure 12.4: Salaries of men and women in a hypothetical firm in thousand Euro. The line is a linear model (<code>salary ~ gender</code>) fitted to the data.
</p>
</div>
<p>However, the level of education of these people was also assessed. If we plot this factor together with gender, a completely different picture arises:</p>
<div class="figure"><span id="fig:sal03"></span>
<img src="StatR_files/figure-html/sal03-1.png" alt="The same data as above but now differentiated by education. The lines are a linear model (`salary ~ gender * education`) fitted to the data. As you notice, a model `salary ~ gender + education` might be more suitable, because the slopes don't seem to differ much (_i.e._ there is probably no interaction effect)." width="672" />
<p class="caption">
Figure 12.5: The same data as above but now differentiated by education. The lines are a linear model (<code>salary ~ gender * education</code>) fitted to the data. As you notice, a model <code>salary ~ gender + education</code> might be more suitable, because the slopes don’t seem to differ much (<em>i.e.</em> there is probably no interaction effect).
</p>
</div>
<p>The slopes in this figure are definitely positive, showing that there is a difference in salary between men and women: men are paid better than women in the same education class. The difference is approximately 2.5 thousand Euro<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. Why did we not observe that in figure <a href="linearmodels.html#fig:sal02">12.4</a>? The reason is that the data are unbalanced over the four classes (Female-No degree, Female-Degree, Male-No degree, Male-Degree). The females with degree are over-represented, as are the males without degree. This evens out the difference in salary paid, because people with a degree get paid better than people without degree, by approximately 7.6 thousand Euro. If the data had been balanced over all four groups, the difference in salary between men and women would have been evident from a figure like <a href="linearmodels.html#fig:sal02">12.4</a>. In other words, on a <em>balanced</em> data set an ANOVA (or t-test) with only gender as the predictor variable a significant difference between men and women would have shown up, whereas in the current <em>unbalanced</em> data set it doesn’t.</p>
</div>
<div id="exercise-5" class="section level3 unnumbered">
<h3>Exercise</h3>
<ol style="list-style-type: decimal">
<li>It appeared that the plasmid transformation efficiency depended on the way in which the plasmid was prepared. The results analysed above are those for plasmid isolated from the bacterium <em>Escherichia coli</em> (the <em>xenogeneic</em> plasmid preparation). If the plasmid was isolated from <em>Corynebactrium glutamicum</em> itself (a <em>syngeneic</em> plasmid preparation), the transformation numbers were different. The entire data set can be found in the file <a href="data/linearmodels/plasmidtransformation.tab">data/linearmodels/plasmidtransformation.tab</a>. Investigate which model fits the data.
<div>
<a id="LinearmodelsHead3" href="javascript:toggle('LinearmodelsSol3','LinearmodelsHead3');" >Show solution</a>
</div>
<div id="LinearmodelsSol3" style="display: none">
<p>Load and adapt the data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="kw">file.path</span>(baseurl, <span class="st">&#39;data&#39;</span>, <span class="st">&#39;linearmodels&#39;</span>, <span class="st">&#39;plasmidtransformation.tab&#39;</span>)
transforms &lt;-<span class="st"> </span><span class="kw">read.table</span>(f, <span class="dt">sep=</span><span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">head=</span><span class="ot">TRUE</span>)
<span class="co"># we want &#39;normal&#39; as the reference level for temperature</span>
transforms<span class="op">$</span>t &lt;-<span class="st"> </span><span class="kw">relevel</span>(transforms<span class="op">$</span>t, <span class="st">&#39;normal&#39;</span>)
transforms<span class="op">$</span>log.transforms &lt;-<span class="st"> </span><span class="kw">log</span>(transforms<span class="op">$</span>transforms, <span class="dv">10</span>)</code></pre></div>
<p>We compare a model in which plasmidprep is an additive term to a model in which it is an interaction term.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.total.sum &lt;-<span class="st"> </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>plasmidprep <span class="op">+</span><span class="st"> </span>t <span class="op">*</span><span class="st"> </span>h, <span class="dt">data=</span>transforms)
model.total.interact &lt;-<span class="st"> </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>plasmidprep <span class="op">*</span><span class="st"> </span>t <span class="op">*</span><span class="st"> </span>h, <span class="dt">data=</span>transforms)
<span class="kw">anova</span>(model.total.sum, model.total.interact)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: log.transforms ~ plasmidprep + t * h
## Model 2: log.transforms ~ plasmidprep * t * h
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     27 11.3823                                  
## 2     24  1.0161  3    10.366 81.614 9.889e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Which shows that the more complex model is better able to explain the data. The model is so complex, however, that, for the sake of understanding the data, it may be better to fit the data sets for the different plasmid preparations individually. If we fit the data for the syngeneic plasmid praparation individually, we get:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transforms.s &lt;-<span class="st"> </span><span class="kw">subset</span>(transforms, plasmidprep<span class="op">==</span><span class="st">&#39;syngeneic&#39;</span>)
model.s.sum &lt;-<span class="st">  </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>t <span class="op">+</span><span class="st"> </span>h, <span class="dt">data=</span>transforms.s)
model.s.interact &lt;-<span class="st"> </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>t <span class="op">*</span><span class="st"> </span>h, <span class="dt">data=</span>transforms.s)
<span class="kw">anova</span>(model.s.sum, model.s.interact)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: log.transforms ~ t + h
## Model 2: log.transforms ~ t * h
##   Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
## 1     13 0.77907                           
## 2     12 0.73024  1  0.048833 0.8025  0.388</code></pre>
<p>Which shows that the simpler additive model suffices for the syngeneic data. A summary of this model yields</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model.s.sum)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log.transforms ~ t + h, data = transforms.s)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.44544 -0.14049 -0.01294  0.17193  0.34447 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.21062    0.10600  58.589  &lt; 2e-16 ***
## tlow         1.86218    0.12240  15.214 1.16e-09 ***
## hshock       0.07123    0.12240   0.582    0.571    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2448 on 13 degrees of freedom
## Multiple R-squared:  0.9469, Adjusted R-squared:  0.9387 
## F-statistic: 115.9 on 2 and 13 DF,  p-value: 5.169e-09</code></pre>
<p>which suggests that the heat shock has no effect at all. An even simpler model then yields</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.s.tonly &lt;-<span class="st"> </span><span class="kw">lm</span>(log.transforms <span class="op">~</span><span class="st"> </span>t, <span class="dt">data=</span>transforms.s)
<span class="kw">anova</span>(model.s.tonly, model.s.sum)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: log.transforms ~ t
## Model 2: log.transforms ~ t + h
##   Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
## 1     14 0.79936                           
## 2     13 0.77907  1  0.020294 0.3386 0.5706</code></pre>
<p>The anova confirms our suspicion: for the syngeneic DNA preparation the heat shock has no effect on plasmid DNA transformation efficiency!</p>
</div></li>
</ol>
</div>
</div>
<div id="combinations-of-numerical-and-discrete-predictors" class="section level2">
<h2><span class="header-section-number">12.3</span> Combinations of numerical and discrete predictors</h2>
<p>In the linear modeling terminology this is also called ANCOVA (analysis of covariance), because the numerical predictor variables are also called <em>covariates</em>. However again, there is no fundamental difference between this type of model and the previous ones, nor is there a fundamental difference between ANOVA on models with only discrete predictor variables, numerical predictor variables or mixtures of these<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.</p>
<p>As an example, let’s get back to the data that indicated that there is a relation between weight and gender. It is likely that weight is correlated to body height, and one could propose the hypothesis that the relation between gender and weight is actually an indirect one: namely through body height. On average, men are a bity taller than women which could explain the relation observed above. In fact the gender might not have any predictive value anymore if we know body height. We can investigate this hypothesis from the fulll data set found in <a href="data/linearmodels">data/linearmodels</a>. If we plot weight as a function of height we get the following picture:</p>
<p><img src="StatR_files/figure-html/lm10-1.png" width="672" /></p>
<p>It shows a clear relation between height and weight, and it seems like it could be a linear relation. A single straight line through the data was fitted as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">onelinemodel &lt;-<span class="st"> </span><span class="kw">lm</span>(weight<span class="op">~</span>height, <span class="dt">data=</span>bodymetrics)
<span class="kw">summary</span>(onelinemodel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ height, data = bodymetrics)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -18.743  -6.402  -1.231   5.059  41.103 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -105.01125    7.53941  -13.93   &lt;2e-16 ***
## height         1.01762    0.04399   23.14   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.308 on 505 degrees of freedom
## Multiple R-squared:  0.5145, Adjusted R-squared:  0.5136 
## F-statistic: 535.2 on 1 and 505 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The question is whether males and females should be fitted on a single line, or on separate lines. It seems, for example, that the majority of females falls below the common line. Fitting two straight lines, one for males, another for females might yield a better fit. This can be done with one command using the <code>lm()</code> function with the formula <code>weight ~ height * gender</code>, which is equivalent to the formula <code>weight ~ height + gender + height:gender</code>. It includes an additive effect of the two variables <code>gender</code> and <code>height</code> as well as an interaction effect <code>height:gender</code>. The mathematical formula being fitted in terms of the original <code>height</code> variable and the dummy variable <code>gender'</code> is:</p>
<span class="math display" id="eq:bodymet-interaction">\[\begin{equation}
\text{weight} = \beta_0 + \beta_1 \, \text{gender&#39;} + (\beta_2 + \beta_3 \, \text{gender&#39;}) \, \text{height}\tag{12.2}
\end{equation}\]</span>
<p>The four parameters have the following interpretation if the dummy variable equals 0 for females and 1 for males:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>: the offset of the line fitted through female points</li>
<li><span class="math inline">\(\beta_1\)</span>: the <em>difference</em> between the offset for lines fitted through male and female points</li>
<li><span class="math inline">\(\beta_2\)</span>: the slope of the line fitted through female points</li>
<li><span class="math inline">\(\beta_3\)</span>: the <em>difference</em> between the slopes of the lines fitted through the male and female points</li>
</ul>
<p>Essentially, when fitting to eq <a href="linearmodels.html#eq:bodymet-interaction">(12.2)</a> we make the following fits in a single calculation:</p>
<span class="math display">\[\begin{equation*}
   \text{weight} = 
\begin{cases}
    \beta_0 + \beta_2 \, \text{height}, &amp; \text{if gender&#39;} = 0 \, \text{(females)} \\
    \beta_0 + \beta_1 + (\beta_2 + \beta_3) \, \text{height}, &amp; \text{if gender&#39;} = 1 \, \text{(males)}
\end{cases}
\end{equation*}\]</span>
<p>The result is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">twolinesmodel &lt;-<span class="st"> </span><span class="kw">lm</span>(weight <span class="op">~</span><span class="st"> </span>height <span class="op">*</span><span class="st"> </span>gender, <span class="dt">data =</span> bodymetrics)
<span class="kw">summary</span>(twolinesmodel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ height * gender, data = bodymetrics)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -20.187  -5.957  -1.439   4.955  43.355 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -43.81929   13.77877  -3.180  0.00156 ** 
## height           0.63334    0.08351   7.584 1.63e-13 ***
## genderM        -17.13407   19.56250  -0.876  0.38152    
## height:genderM   0.14923    0.11431   1.305  0.19233    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.795 on 503 degrees of freedom
## Multiple R-squared:  0.5682, Adjusted R-squared:  0.5657 
## F-statistic: 220.7 on 3 and 503 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>You should recognize the four parameters in the summary, and you may notice that neither of the two parameters added to the model, relative to the <code>onelinemodel</code> has a significant t-statistic. This may point to an over-fitted model. The ANOVA in the summary compares the residual sum of squares of the model relative to the <strong>nullmodel</strong> which is the model that predicts the weight as the mean of all weights. However, we want to compare this model with two lines to the model with one straight line. This can be done using the <code>anova()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(onelinemodel, twolinesmodel)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: weight ~ height
## Model 2: weight ~ height * gender
##   Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    505 43753                                  
## 2    503 38912  2    4841.5 31.292 1.553e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>which shows that the <code>twolines</code> model does fit significantly better on the data using the two additional degrees of freedom. The fit with two lines is shown in the figure below:</p>
<p><img src="StatR_files/figure-html/unnamed-chunk-236-1.png" width="672" /></p>
<p>It suggests why having two additional parameters might lead to over-fitting of the data: the slopes of the two lines differ only slightly, and might actually be the same. Fitting two lines with a single slope but different offsets is done with the <code>lm()</code> function using the formula <code>weight ~ height + gender</code>, <em>i.e</em> without the interaction effect of the previous model. The mathematical formula of this fit is</p>
<span class="math display" id="eq:bodymet-additive">\[\begin{equation}
\text{weight} = \beta_0 + \beta_1 \, \text{gender&#39;} + \beta_2 \, \text{height}\tag{12.3}
\end{equation}\]</span>
<p>which is a model with three instead of four parameters. Essentially, when fitting to eq <a href="linearmodels.html#eq:bodymet-additive">(12.3)</a> we make the following fits in a single calculation:</p>
<span class="math display">\[\begin{equation*}
   \text{weight} = 
\begin{cases}
  \beta_0 + \beta_2 \, \text{height} &amp; \text{if gender&#39;} = 0 \, \text{(females)} \\
  \beta_0 + \beta_1 + \beta_2 \, \text{height} &amp; \text{if gender&#39;} = 1 \, \text{(males)}
\end{cases}
\end{equation*}\]</span>
<p>The interpretation of the parameters is:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>: the offset of the line fitted through female points</li>
<li><span class="math inline">\(\beta_1\)</span>: the <em>difference</em> between the offset for lines fitted through male and female points</li>
<li><span class="math inline">\(\beta_2\)</span>: the slope of the lines fitted through male and female points</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">singleslopemodel &lt;-<span class="st"> </span><span class="kw">lm</span>(weight <span class="op">~</span><span class="st"> </span>height <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> bodymetrics)
<span class="kw">summary</span>(singleslopemodel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ height + gender, data = bodymetrics)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -20.184  -5.978  -1.356   4.709  43.337 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -56.94949    9.42444  -6.043 2.95e-09 ***
## height        0.71298    0.05707  12.494  &lt; 2e-16 ***
## genderM       8.36599    1.07296   7.797 3.66e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.802 on 504 degrees of freedom
## Multiple R-squared:  0.5668, Adjusted R-squared:  0.5651 
## F-statistic: 329.7 on 2 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The addition of the gender variable no does show a high value for the t-statistic. We can compare the residual sums of squares of the two models using the <code>anova()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(singleslopemodel, twolinesmodel)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: weight ~ height + gender
## Model 2: weight ~ height * gender
##   Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)
## 1    504 39043                           
## 2    503 38912  1    131.84 1.7043 0.1923</code></pre>
<p>It shows that the addition of an interaction effect (differen slopes for female and male points) does not significantly reduce the residual sum of squares, as expressed by the low F-statistic (1.7) and correspondingly high p-value of 0.192.</p>
<div id="exercises-9" class="section level3 unnumbered">
<h3>Exercises</h3>
<ol style="list-style-type: decimal">
<li>A different model with only three parameters would be one with a single intercept and different slopes. Fit this model and compare it to the model with two independent lines using ANOVA.
<div>
<a id="LinearmodelsHead4" href="javascript:toggle('LinearmodelsSol4','LinearmodelsHead4');" >Show solution</a>
</div>
<div id="LinearmodelsSol4" style="display: none">
<div class="rmdconstruction">

</div>
</div></li>
<li>A third covariate in the dataset is <code>age</code>. Make a plot of weight as a function of age, possibly seprately for males and females. Try whether adding <code>age</code> to the model improves the predictability of weight. Start with the simplest model without interaction effects on <code>age</code>.<br />

<div>
<a id="LinearmodelsHead5" href="javascript:toggle('LinearmodelsSol5','LinearmodelsHead5');" >Show solution</a>
</div>
<div id="LinearmodelsSol5" style="display: none">
<div class="rmdconstruction">

</div>
</div></li>
</ol>
</div>
</div>
<div id="the-connection-between-linear-models-and-anova" class="section level2">
<h2><span class="header-section-number">12.4</span> The connection between linear models and ANOVA</h2>
<p>The combination of the two techniques, Linear Modeling and Analysis of Variance, in the title of this chapter is not a coincidence. The question is justified whether ANOVA could not also be applied to residual sums of squares to compare fits of two non-linear models. The answer is that it can … in principle. However, there are two problems:</p>
<ol style="list-style-type: decimal">
<li>The traditional ANOVA is used as a way to compare models that differ by a single predictor variable or term, to find out whether this variable or term has any predictive value. This procedure is not easily implemented in non-linear equations, where adding a term in a denominator, for example, may completely change the nature of the relation between predictor and response variables, also for the other variables or terms.</li>
<li>In contrast to fits with linear equations, the number of <strong>degrees of freedom</strong> of a fit with a non-linear equation is ususally not well-defined. We need these degrees of freedom to be able to calculate the F-statistic. Hence, the F-statistic can only be calculated if a procedure exists that allows a reasonable estimation of the degrees of freedom of a fit.</li>
</ol>
<p>For model selection with non-linear equations, other criteria than ANOVA, like the Akaike Information Criterion (AIC) and Bayes Information Criterion (BIC) may be more suitable. These measures of statistical appropriateness of fits are not based on the relatively limited assumptions underlying the F-statistic.</p>
<div class="rmdtip">
<p>Consider using the <a href="https://cran.r-project.org/web/packages/broom/vignettes/broom.html"><code>broom</code></a> package when analyzing statistical models. The output of the <code>broom</code> functions is, in contrast to the standard print and summaries of <code>lm</code> and other model-fit objects, always a data frame. The latter is much easier to extract data, like coefficients and p-values from. For example, instead of <code>summary(singleslopemodel)</code>, we could use</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(singleslopemodel)</code></pre></div>
<pre><code>##          term    estimate  std.error statistic      p.value
## 1 (Intercept) -56.9494889 9.42443771 -6.042747 2.948023e-09
## 2      height   0.7129752 0.05706608 12.493852 2.149494e-31
## 3     genderM   8.3659935 1.07295815  7.797129 3.661279e-14</code></pre>
<p>to obtain the coefficients and their statistics, and</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(singleslopemodel)</code></pre></div>
<pre><code>##   r.squared adj.r.squared    sigma statistic      p.value df    logLik
## 1 0.5667784     0.5650593 8.801535  329.6884 2.824545e-92  3 -1820.585
##       AIC      BIC deviance df.residual
## 1 3649.17 3666.084 39043.38         504</code></pre>
<p>which yields several quality-of-fit metrics, including AIC and BIC.</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Faraway2005">
<p>Faraway, J. 2005. <em>Linear Models with R</em>. Boca Raton, FL, USA: Chapman &amp; Hall/CRC. <a href="http://www.maths.bath.ac.uk/~jjf23/LMR/" class="uri">http://www.maths.bath.ac.uk/~jjf23/LMR/</a>.</p>
</div>
<div id="ref-James2013">
<p>James, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Springer Texts in Statistics. New York: Springer. <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a>.</p>
</div>
<div id="ref-Rest1999">
<p>Rest, M. E. van der, C. Lange, and D. Molenaar. 1999. “A Heat Shock Following Electroporation Induces Highly Efficient Transformation of <em>Corynebacterium Glutamicum</em> with Xenogeneic Plasmid DNA.” <em>Appl. Microbiol. Biotechnol.</em> 52 (4): 541–45. doi:<a href="https://doi.org/10.1007/s002530051557">10.1007/s002530051557</a>.</p>
</div>
<div id="ref-Zahn2010">
<p>Zahn, I. 2010. “Working with Unbalanced Cell Sizes in Multiple Regression with Categorical Predictors.” <a href="http://psychology.okstate.edu/faculty/jgrice/psyc5314/SS_types.pdf" class="uri">http://psychology.okstate.edu/faculty/jgrice/psyc5314/SS_types.pdf</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>No reason to freak out (yet), this is hypothetical data.<a href="linearmodels.html#fnref6">↩</a></p></li>
<li id="fn7"><p>Don’t be intimidated by the terminology used in this field. It sometimes seems as though there are many, completely different types of ANOVA. To me, understanding came when I realized that it all boils down to a single trick: fit two linear equations, compare residual sums of squares with F-test.<a href="linearmodels.html#fnref7">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="distributions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hubble.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "libs/mathjax-local/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
